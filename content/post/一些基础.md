---
author: "momo"
date: 2022-09-03
title: "一些基础"
categories: [
    "论文笔记",
]
---

## mlp

博客：https://zhuanlan.zhihu.com/p/63184325

pytorch：https://blog.csdn.net/rocketeerLi/article/details/92158767 改正如下

https://blog.csdn.net/geter_CS/article/details/84857220

mnist：https://zhuanlan.zhihu.com/p/36592188



## code

```python
'''
mlp 最后结果
epoch:19	avg training loss:0.022919857291857866
accuracy of val dataset is 97.88
'''

import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision import datasets
from torchvision import transforms
from torch.utils.data import DataLoader

# 定义全局变量
n_epochs = 20  # epoch 的数目
batch_size = 16  # 决定每次读取多少图片

# 定义训练集 测试集，如果找不到数据，就下载
train_data = datasets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())
test_data = datasets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())

print('data loaded!')

# 创建加载器
train_loader = DataLoader(train_data, batch_size=batch_size, num_workers=0)
test_loader = DataLoader(test_data, batch_size=batch_size, num_workers=0)


# 建立一个四层感知机网络
class MLP(nn.Module):
    def __init__(self):
        super(MLP, self).__init__()
        # 2个隐藏层 1个输出层
        self.fc1 = nn.Linear(784, 512)
        self.fc2 = nn.Linear(512, 128)
        self.fc3 = nn.Linear(128, 10)

    def forward(self, x):
        x = x.view(-1, 28 * 28)  # ---> (bs,784)
        out = F.relu(self.fc1(x))
        out = F.relu(self.fc2(out))
        out = F.relu(self.fc3(out))
        # out = F.softmax(out, dim=1) 这个是不需要的
        return out


def train():
    # 定义损失函数和优化器
    model = MLP()
    print('model loaded!')
    loss_fc = torch.nn.CrossEntropyLoss()
    optimizer = torch.optim.SGD(params=model.parameters(), lr=0.01)

    for epoch in range(n_epochs):
        # train
        model.train()
        train_loss = 0.0
        for i, (data, target) in enumerate(train_loader):
            optimizer.zero_grad()
            output = model(data)
            loss = loss_fc(output, target)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * data.size(0)
        train_loss = train_loss / (len(train_loader.dataset))
        print(f'epoch:{epoch}\tavg training loss:{train_loss}')

        # val
        model.eval()
        correct = 0
        total = 0
        with torch.no_grad():
            for data, target in test_loader:
                output = model(data)
                output = F.softmax(output, dim=1)
                _, predicted = torch.max(output.data, 1)
                total += data.size(0)
                correct += (predicted == target).sum().item()
        print(f'accuracy of val dataset is {100.0 * correct / total}')

if __name__ == '__main__':
    train()
```



## 动态mlp

博客：https://blog.csdn.net/odssodssey/article/details/124099498

(bs,channels) 大小的img_feature 和 text_feature 融合



## 我的启发

准备数据：原始数据是：**<u>图片</u>**（16，3，256，256）和**<u>类别标签</u>**

1、根据类别标签，可以获得<u>**区域标签**</u>

2、**<u>辅助信息</u>**，始终是固定的，是一个（（瞳孔、结膜、角膜）300）的tensor

制作数据集：如上四类数据。数据：图片+辅助信息；标签：类别标签+区域标签

前向计算：1.图片经过backbone提取，预测得到区域标签；2.预测得到的区域标签值，与后面的特征提取模块融合，帮助分类，推测得到最终的类别标签。

loss计算：[BCELoss, BCELoss] 两个loss。平均（动态分配）作为最终loss。

## 

![截屏2022-08-23 上午10.19.22](/Users/momochan/Library/Application Support/typora-user-images/截屏2022-08-23 上午10.19.22.png)



## 网络架构（d）MSFA——多尺度特征融合模块

![截屏2022-08-23 下午12.45.00](/Users/momochan/Library/Application Support/typora-user-images/截屏2022-08-23 下午12.45.00.png)

## byte pair encoding

https://blog.csdn.net/m0_37962192/article/details/117417537

https://anaconda.org/powerai/bpemb



## result

5个数据集

## ![截屏2022-08-25 下午6.50.35](/Users/momochan/Library/Application Support/typora-user-images/截屏2022-08-25 下午6.50.35.png)
