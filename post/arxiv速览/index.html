<!doctype html><html lang=zh-cn itemscope itemtype=http://schema.org/WebPage><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><title>arxiv速览 - ODYSSEY</title><meta name=renderer content="webkit"><meta name=viewport content="width=device-width,initial-scale=1,user-scalable=yes"><meta name=MobileOptimized content="width"><meta name=HandheldFriendly content="true"><meta name=applicable-device content="pc,mobile"><meta name=theme-color content="#f8f5ec"><meta name=msapplication-navbutton-color content="#f8f5ec"><meta name=apple-mobile-web-app-capable content="yes"><meta name=apple-mobile-web-app-status-bar-style content="#f8f5ec"><meta name=mobile-web-app-capable content="yes"><meta name=author content="momo"><meta name=description content="1篇arxiv最新的摘要和关键词提取（分类/分割相关）（5.6-5.12） 1、Robust Medical Image Classification from Noisy Labeled Data with Global and Local Representation Guided Co-training 全局和局部表示引导联合"><meta name=generator content="Hugo 0.104.3"><link rel=canonical href=http://odyssey.halfbit.top/post/arxiv%E9%80%9F%E8%A7%88/><link rel=icon href=/favicon.ico><link rel=stylesheet href=/sass/jane.min.fa4b2b9f31b5c6d0b683db81157a9226e17b06e61911791ab547242a4a0556f2.css integrity="sha256-+ksrnzG1xtC2g9uBFXqSJuF7BuYZEXkatUckKkoFVvI=" media=screen crossorigin=anonymous><meta property="og:title" content="arxiv速览"><meta property="og:description" content="1篇arxiv最新的摘要和关键词提取（分类/分割相关）（5.6-5.12） 1、Robust Medical Image Classification from Noisy Labeled Data with Global and Local Representation Guided Co-training 全局和局部表示引导联合"><meta property="og:type" content="article"><meta property="og:url" content="http://odyssey.halfbit.top/post/arxiv%E9%80%9F%E8%A7%88/"><meta property="article:section" content="post"><meta property="article:published_time" content="2022-05-12T00:00:00+00:00"><meta property="article:modified_time" content="2022-05-12T00:00:00+00:00"><meta itemprop=name content="arxiv速览"><meta itemprop=description content="1篇arxiv最新的摘要和关键词提取（分类/分割相关）（5.6-5.12） 1、Robust Medical Image Classification from Noisy Labeled Data with Global and Local Representation Guided Co-training 全局和局部表示引导联合"><meta itemprop=datePublished content="2022-05-12T00:00:00+00:00"><meta itemprop=dateModified content="2022-05-12T00:00:00+00:00"><meta itemprop=wordCount content="8137"><meta itemprop=keywords content><meta name=twitter:card content="summary"><meta name=twitter:title content="arxiv速览"><meta name=twitter:description content="1篇arxiv最新的摘要和关键词提取（分类/分割相关）（5.6-5.12） 1、Robust Medical Image Classification from Noisy Labeled Data with Global and Local Representation Guided Co-training 全局和局部表示引导联合"><!--[if lte IE 9]><script src=https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js></script><![endif]--><!--[if lt IE 9]><script src=https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js></script>
<script src=https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js></script><![endif]--></head><body><div id=mobile-navbar class=mobile-navbar><div class=mobile-header-logo><a href=/ class=logo>ODYSSEY</a></div><div class=mobile-navbar-icon><span></span>
<span></span>
<span></span></div></div><nav id=mobile-menu class="mobile-menu slideout-menu"><ul class=mobile-menu-list><li class=mobile-menu-item><a class=menu-item-link href=http://odyssey.halfbit.top/>Home</a></li><li class=mobile-menu-item><a class=menu-item-link href=http://odyssey.halfbit.top/post/>Archives</a></li><li class=mobile-menu-item><a class=menu-item-link href=http://odyssey.halfbit.top/categories/>Categories</a></li><li class=mobile-menu-item><a class=menu-item-link href=http://odyssey.halfbit.top/about/>About</a></li></ul></nav><link rel=stylesheet href=/lib/photoswipe/photoswipe.min.css><link rel=stylesheet href=/lib/photoswipe/default-skin/default-skin.min.css><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)"></button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><header id=header class="header container"><div class=logo-wrapper><a href=/ class=logo>ODYSSEY</a></div><nav class=site-navbar><ul id=menu class=menu><li class=menu-item><a class=menu-item-link href=http://odyssey.halfbit.top/>Home</a></li><li class=menu-item><a class=menu-item-link href=http://odyssey.halfbit.top/post/>Archives</a></li><li class=menu-item><a class=menu-item-link href=http://odyssey.halfbit.top/categories/>Categories</a></li><li class=menu-item><a class=menu-item-link href=http://odyssey.halfbit.top/about/>About</a></li></ul></nav></header><div id=mobile-panel><main id=main class="main bg-llight"><div class=content-wrapper><div id=content class="content container"><article class="post bg-white"><header class=post-header><h1 class=post-title>arxiv速览</h1><div class=post-meta><time datetime=2022-05-12 class=post-time>2022-05-12</time><div class=post-category><a href=http://odyssey.halfbit.top/categories/arxiv/>arxiv</a>
<a href=http://odyssey.halfbit.top/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/>论文笔记</a></div></div></header><div class=post-toc id=post-toc><h2 class=post-toc-title>文章目录</h2><div class=post-toc-content><nav id=TableOfContents></nav></div></div><div class=post-content><p>1篇arxiv最新的摘要和关键词提取（分类/分割相关）（5.6-5.12）</p><ul><li>1、Robust Medical Image Classification from Noisy Labeled Data with Global and Local Representation Guided Co-training<ul><li>全局和局部表示引导联合训练的含噪标签数据的稳健医学图像分类</li><li>深度神经网络在各种自然图像和医学图像计算任务中取得了显著的成功。然而，这些成就离不开精确标注的训练数据。如果遇到一些有噪声的标记图像，网络训练过程会遇到困难，导致出现次优分类器。这一问题在医学图像分析领域更为严重，因为医学图像的注释质量在很大程度上依赖于注释者的专业知识和经验。在本文中，我们提出了一种新的具有全局和局部表示学习的协作训练范式，用于从有噪声的标记数据中进行鲁棒的医学图像分类，以解决高质量标注医学数据的不足。具体来说，我们采用带噪声标签滤波器的自集成模型来有效地选择干净和噪声样本。然后，通过协作训练策略对干净样本进行训练，以消除不完美标记样本的干扰。值得注意的是，我们进一步设计了一种新的全局和局部表示学习方案，隐式地正则化网络，以自监督方式利用噪声样本。我们在四个公共医学图像分类数据集上评估了我们提出的鲁棒学习策略，这些数据集具有三种类型的标签噪声，即随机噪声、计算机生成的标签噪声和观察者之间的变异性噪声。我们的方法优于其他噪声标签学习方法，我们还进行了大量实验来分析我们方法的每个组成部分。</li></ul></li></ul><p>20篇arxiv最新的摘要和关键词提取（分类/分割相关）（4.22-5.5）</p><ul><li>1、Noise-reducing attention cross fusion learning transformer for histological image classification of osteosarcom<ul><li>去噪注意交叉融合学习转换器用于骨肉瘤组织学图像分类</li><li>骨肉瘤的恶性程度及其转移/扩散趋势主要取决于病理分级（通过在显微镜下观察肿瘤的形态确定）。本研究的目的是利用人工智能对骨肉瘤组织学图像进行分类，并评估肿瘤的存活和坏死情况，这将有助于医生减少工作量，提高骨肉瘤癌症检测的准确性，改善患者的预后。该研究提出了一种典型的Transformer图像分类框架，将降噪卷积自动编码器和特征交叉融合学习（NRCA-FCFL）相结合，对骨肉瘤组织学图像进行分类。降噪卷积自动编码器可以很好地去除骨肉瘤组织学图像的噪声，从而获得更纯净的骨肉瘤分类图像。此外，我们还引入了特征交叉融合学习，它集成了两个尺度的图像块，通过使用额外的分类标记来充分探索它们之间的相互作用。结果，生成一个细化的融合特征，并将其反馈给残差神经网络进行标签预测。我们进行了大量实验来评估所提出方法的性能。实验结果表明，该方法在各种评价指标上均优于传统的深度学习方法，支持骨肉瘤诊断的准确率为99.17%。</li><li>骨肉瘤，去噪，转化器，特征融合，框架，诊断</li></ul></li><li>2、CLIP-Art: Contrastive Pre-training for Fine-Grained Art Classification<ul><li>剪贴画：细粒度艺术分类的对比性预训练</li><li>现有的计算机视觉研究在艺术品的细粒度属性识别和缺乏精心策划的注释数据集方面存在困难，因为它们的创建成本很高。据我们所知，我们是最早使用CLIP（对比语言图像预训练）在各种艺术品图像和文本描述对上训练神经网络的方法之一。CLIP能够直接从自由形式的艺术描述中学习，或者，如果有的话，可以从精心策划的细粒度标签中学习。该模型的零拍功能允许预测给定图像的准确自然语言描述，而无需直接优化任务。我们的方法旨在解决两个挑战：实例检索和细粒度艺术品属性识别。我们使用IMT数据集，我们认为它是最大的带注释的艺术品数据集。在这个基准测试中，我们仅通过自我监督就取得了有竞争力的结果。</li></ul></li><li>3、Application of machine learning methods to detect and classify Core images using GAN and texture recognition<ul><li>基于GaN和纹理识别的机器学习方法在岩心图像检测与分类中的应用</li><li>在勘探活动中，石油公司严重依赖钻井岩芯样本，因为它们提供有价值的地质信息，帮助它们找到重要的石油矿藏。传统的岩心测井技术费时费力且主观。岩芯成像是石油工业中的一项新技术，通过以无损和无创的方式快速描述大量岩心的特征来补充分析。在本文中，我们将提出核心检测和分类的问题。第一个问题是分别使用更快的RCNN和Mask RCNN模型来检测图像中的核和分割孔洞。第二个问题是通过应用生成对抗网络（GAN）技术和使用上下文残差聚合（CRA）来填补核心图像中的漏洞，该聚合为图像中缺失的内容创建高频残差。最后应用纹理识别模型对岩心图像进行分类。</li></ul></li><li>4、Understanding the impact of image and input resolution on deep digital pathology patch classifiers<ul><li>了解图像和输入分辨率对深度数字病理斑块分类器的影响</li><li>我们认为，在数字病理学（DP）中，注释是一种有效的学习方式，专家注释的费用很高，因此很少。我们探讨了图像和输入分辨率对DP斑块分类性能的影响。我们使用两个癌症斑块分类数据集PCam和CRC来验证我们的研究结果。我们的实验表明，在注释稀少和注释丰富的环境中，通过同时操纵图像和输入分辨率，可以提高面片分类的性能。我们在两个数据集上都显示了图像和输入分辨率以及斑块分类精度之间的正相关关系。通过利用图像和输入分辨率，我们在小于1%的数据上训练的最终模型与在PCam数据集的原始图像分辨率下在100%的数据上训练的模型表现相同。</li></ul></li><li>5、On the generalization capabilities of FSL methods through domain adaptation: a case study in endoscopic kidney stone image classification<ul><li>基于领域自适应的FSL方法泛化能力研究&ndash;以内窥镜肾结石图像分类为例</li><li>深度学习在计算机视觉的各个领域，如图像分类、目标检测和语义分割等方面显示出巨大的潜力。然而，正如反复证明的那样，由于数据分布的变化，在数据集上训练的深度学习方法不能很好地推广到其他领域的数据集，甚至不能推广到类似的数据集。在这项工作中，我们建议使用基于元学习的Few-Shot学习方法来缓解这些问题。为了证明其有效性，我们使用了两组不同内窥镜和不同采集条件采集的肾结石样本数据集。结果表明，在5路5拍和5路20拍设置下，这种方法的准确度分别达到74.38%和88.52%，从而能够处理域偏移。相反，在同一数据集中，传统的深度学习（DL）方法的准确率仅为45%。</li></ul></li><li>6、MS Lesion Segmentation: Revisiting Weighting Mechanisms for Federated Learning<ul><li>多发性硬化症病变分割：重新审视联合学习的加权机制</li><li>联邦学习（FL）已被广泛用于医学图像分析，以促进多客户端协作学习，而无需共享原始数据。尽管取得了巨大成功，但由于不同扫描仪和采集参数所赋予的病变特征存在差异，FL在多发性硬化（MS）病变分割任务中的性能有限。在这项工作中，我们通过两种有效的重新加权机制提出了第一个FL MS病变分割框架。具体来说，在聚合过程中，根据每个局部节点的分段性能，为其分配一个可学习的权重。此外，还根据训练期间数据的病变体积对每个客户的分割损失函数重新加权。使用公共数据集和临床数据集对两种FL-MS分割场景进行的对比实验表明，该方法的有效性显著优于其他FL方法。此外，结合我们提出的聚合机制的FL的分割性能可以超过所有原始数据的集中训练。广泛的评估也表明了我们的方法在估计损伤修复后的脑体积差异时的优越性。</li></ul></li><li>7、A Comprehensive Survey of Image Augmentation Techniques for Deep Learning<ul><li>面向深度学习的图像增强技术综述</li><li>深度学习在需要大量图像的计算机视觉中取得了良好的性能，然而，在许多情况下，收集图像既昂贵又困难。为了缓解这个问题，许多图像增强算法被认为是有效的策略。了解当前的算法对于为给定任务找到合适的方法或开发新技术至关重要。在本文中，我们使用一种新的信息分类法对用于深度学习的图像增强进行了全面的调查。为了了解为什么我们需要图像增强，我们介绍了计算机视觉任务和邻近分布中的挑战。然后，将算法分为三类；无模型、基于模型和基于策略的优化。无模型类别采用图像处理方法，而基于模型的方法利用可训练的图像生成模型。相比之下，基于优化策略的方法旨在找到最优操作或它们的组合。此外，我们还讨论了两个更为活跃的主题，即利用不同的方法来理解图像增强，如群理论和核理论，以及将图像增强用于无监督学习的当前趋势。基于这些分析，我们相信我们的调查提供了一个更好的理解，有助于选择合适的方法或为实际应用设计新的算法。</li></ul></li><li>8、Dual Cross-Attention Learning for Fine-Grained Visual Categorization and Object Re-Identification (CVPR 2022)<ul><li>基于双重交叉注意学习的细粒度视觉分类与目标再识别</li><li>最近，自我注意机制在各种NLP和CV任务中表现出了令人印象深刻的性能，这有助于捕捉序列特征并获得全局信息。在这项工作中，我们探索了如何扩展自我注意模块，以便更好地学习细微特征嵌入，以识别细粒度对象，例如不同的鸟类物种或个人身份。为此，我们提出了一种双交叉注意学习（DCAL）算法来协调自我注意学习。首先，我们提出了全局-局部交叉注意（GLCA）来增强全局图像和局部高响应区域之间的相互作用，这有助于增强识别的空间分辨线索。其次，我们提出了成对交叉注意（PWCA）来建立图像对之间的相互作用。PWCA可以通过将另一幅图像视为干扰物来调节图像的注意力学习，并在推理过程中被移除。我们观察到，DCAL可以减少误导性注意，并分散注意反应，从而发现更多互补的识别部分。我们对细粒度视觉分类和对象重新识别进行了广泛的评估。实验表明，DCAL的表现与最先进的方法不相上下，并不断提高多个自我注意基线，例如，在MSMT17上分别超过DeiT Tiny和ViT Base 2.8%和2.4%。</li></ul></li><li>9、MIRST-DM: Multi-Instance RST with Drop-Max Layer for Robust Classification of Breast Cancer<ul><li>MIRST-DM：用于乳腺癌稳健分类的Drop-Max层多实例RST</li><li>鲁棒自训练（RST）可以增强图像分类模型的对抗性鲁棒性，而不会显著牺牲模型的通用性。然而，RST和其他最先进的防御方法未能在小型医学图像集上保持通用性并重现其良好的对抗鲁棒性。在这项工作中，我们提出了具有drop max层的多实例RST，即MIRST-DM，它在训练期间涉及一系列迭代生成的对抗性实例，以在小数据集上学习更平滑的决策边界。建议的drop max层消除了不稳定的特征，并帮助学习对图像扰动具有鲁棒性的表示。使用一个包含1190张图像的小型乳腺超声数据集对所提出的方法进行了验证。结果表明，该方法对三种常见攻击具有最先进的对抗鲁棒性。</li></ul></li><li>10、Deep Multi-Scale U-Net Architecture and Noise-Robust Training Strategies for Histopathological Image Segmentation<ul><li>组织病理学图像分割的深度多尺度U网结构及抗噪训练策略</li><li>虽然U-Net体系结构已被广泛用于医学图像分割，但我们在这项工作中解决了它的两个缺点。首先，当用于分割的目标区域在形状和大小上表现出显著变化时，vanilla U-Net的精度会下降。尽管U-Net已经具备了在不同尺度上分析特征的能力，但我们建议在U-Net编码器的每个卷积模块中明确添加多尺度特征映射，以改进组织学图像的分割。其次，当有监督学习的注释有噪声或不完整时，U-Net模型的准确性也会受到影响。这可能是因为人类专家很难非常精确地识别和描述特定病理学的所有实例。我们通过引入辅助置信图来应对这一挑战，这些辅助置信图较少强调给定目标区域的边界。此外，我们利用深度网络的自举特性智能地解决缺少注释的问题。在我们对乳腺癌淋巴结的私人数据集进行的实验中，主要任务是分割生发中心和窦组织细胞增生症，我们观察到，基于两个拟议的增强，与U-Net基线相比，有显著改善。</li></ul></li><li>11、PolyLoss: A Polynomial Expansion Perspective of Classification Loss Functions<ul><li>PolyLoss：分类损失函数的多项式展开</li><li>交叉熵损失和焦点损失是训练深度神经网络解决分类问题时最常见的选择。但是，一般来说，一个好的损失函数可以采用更灵活的形式，并且应该针对不同的任务和数据集进行定制。基于函数可以通过泰勒展开进行近似，我们提出了一个简单的框架，名为PolyLoss，将损失函数视为多项式函数的线性组合，并进行设计。我们的PolyLoss允许根据目标任务和数据集轻松调整不同多项式基的重要性，同时自然地将上述交叉熵损失和焦点损失纳入特殊情况。大量实验结果表明，PolyLoss中的最佳选择确实取决于任务和数据集。只需引入一个额外的超参数并添加一行代码，我们的Poly-1公式在二维图像分类、实例分割、对象检测和三维对象检测任务上的性能就超过了交叉熵损失和焦点损失，有时甚至大幅度超过。</li></ul></li><li>12、A survey on attention mechanisms for medical applications: are we moving towards better algorithms?<ul><li>医学应用中注意力机制的调查：我们正在朝着更好的算法发展吗？</li><li>在计算机视觉和自然语言处理的深度学习算法中，注意力机制的日益普及使得这些模型对其他研究领域具有吸引力。在医疗保健领域，迫切需要能够改善临床医生和患者日常生活的工具。自然，基于注意的算法在医学应用中的应用进展顺利。然而，由于医疗保健是一个依赖于高风险决策的领域，科学界必须考虑这些高性能算法是否适合医疗应用的需要。基于这一座右铭，本文广泛回顾了机器学习（包括Transformer）中注意机制在几种医学应用中的使用。这项工作有别于前人，它通过对三种不同使用案例的医学图像分类实验案例研究，对文献中提出的注意机制的主张和潜力进行了批判性分析。这些实验的重点是将注意力机制的过程整合到已建立的深度学习架构中，分析它们的预测能力，以及通过事后解释方法生成的显著性图的视觉评估。本文最后对有关注意机制的文献中提出的主张和潜力进行了批判性分析，并提出了可能受益于这些框架的未来医学应用研究方向。</li></ul></li><li>13、Contrastive learning-based computational histopathology predict differential expression of cancer driver genes<ul><li>基于对比学习的计算组织病理学预测肿瘤驱动基因的差异表达</li><li>数字病理分析是用于癌症诊断的主要检查。近年来，深入学习驱动的病理图像特征提取能够检测基因变异和肿瘤环境，但很少有研究关注肿瘤细胞中的差异基因表达。在本文中，我们提出了一个自我监督的对比学习框架HistCode，用于从整张幻灯片图像（WSIs）中推断差异基因表达。我们利用大规模非注释WSI的对比学习，在潜伏期获得幻灯片级别的组织病理学特征，然后将其转移到肿瘤诊断和预测差异表达的癌症驱动基因。我们的大量实验表明，在肿瘤诊断任务中，我们的方法优于其他最先进的模型，并且能够有效地预测差异基因表达。有趣的是，我们发现高倍变化的基因可以更精确地预测。为了直观地说明从病理图像中提取信息特征的能力，我们在空间上可视化了由图像块的关注分数着色的WSI。我们发现肿瘤和坏死区域与经验丰富的病理学家的注释高度一致。此外，淋巴细胞特异性基因表达模式产生的空间热图也与人工标记的WSI一致。</li></ul></li><li>14、OCFormer: One-Class Transformer Network for Image Classification<ul><li>OCFormer：一类图像分类变换网络</li><li>我们提出了一种新的基于视觉变换器（ViT）的单类深度学习框架。其核心思想是使用零中心高斯噪声作为潜在空间表示的伪负类，然后使用最佳损失函数训练网络。在以前的工作中，人们已经付出了巨大的努力来学习使用各种损失函数的良好表示，这确保了区分性和紧凑性。在CIFAR-10、CIFAR-100、Fashion MNIST和CelebA眼镜数据集上对所提出的单级视觉转换器（OCFORER）进行了详尽的实验。与基于CNN的单类分类器方法相比，我们的方法有了显著的改进。</li></ul></li><li>15、Learning by Erasing: Conditional Entropy based Transferable Out-Of-Distribution Detection<ul><li>擦除学习：基于条件熵的可转移失配检测</li><li>分布外（OOD）检测对于处理训练和测试场景之间的分布转移至关重要。对于一个新的分布内（ID）数据集，现有的方法需要重新训练来捕获数据集特定的特征表示或数据分布。在本文中，我们提出了一种基于深度生成模型（DGM）的可转移OOD检测方法，该方法不需要在新的ID数据集上重新训练。我们设计了一种图像擦除策略，为每个ID数据集配备唯一的条件熵分布，这决定了DGM的后验不确定性分布在不同ID数据集上的差异。由于卷积神经网络具有强大的表示能力，在复杂数据集上训练的模型可以在不进行再训练的情况下捕获ID数据集之间的上述差异，从而实现可转移的OOD检测。我们在五个数据集上验证了所提出的方法，并验证了我们的方法达到了与最先进的基于组的OOD检测方法相当的性能，这些方法需要重新训练才能部署在新的ID数据集上。我们的代码可在https://github.com/oOHCIOo/CETOOD.</li></ul></li><li>16、Detecting Recolored Image by Spatial Correlation</li><li>基于空间相关的彩色图像检测</li><li>图像取证旨在确保图像的真实性，在过去几十年中，在处理常见的图像操作（如拷贝移动、拼接和修复）方面取得了巨大进展。然而，只有少数研究人员关注一种新兴的编辑技术，称为图像重新着色，它可以操纵图像的颜色值，赋予图像一种新的风格。为了防止它被恶意使用，以前的方法从通道间相关性和光照一致性的角度解决了传统的重新存储问题。在本文中，我们试图从空间相关性的角度探索一种解决方案，它展示了常规和基于深度学习的再存储的通用检测能力。通过理论和数值分析，我们发现重新排序操作将不可避免地破坏像素之间的空间相关性，这意味着一种新的统计可分辨性先验。基于这一事实，我们生成一组空间相关特征，并通过卷积神经网络从这些特征中学习信息表示。为了训练我们的网络，我们使用三种重新排序方法来生成大规模和高质量的数据集。在两个重采样场景中的大量实验结果表明，空间相关特征具有很高的分辨能力。我们的方法在多个基准数据集上达到了最先进的检测精度，并且对未知类型的重新排序方法具有良好的泛化能力。</li><li>17、Evaluation of Multi-Scale Multiple Instance Learning to Improve Thyroid Cancer Classification<ul><li>多尺度多实例学习改进甲状腺癌分类的评价</li><li>甲状腺癌是目前女性第五常见的恶性肿瘤。由于癌症亚型的鉴别对治疗和当前的治疗非常重要，手动方法耗时且主观，因此计算机辅助癌症类型的自动鉴别至关重要。甲状腺癌的手动鉴别是基于组织切片，由病理学家利用组织学特征进行分析。由于千兆像素整张幻灯片图像的巨大尺寸，使用深度学习方法进行整体分类是不可行的。基于补丁的多实例学习方法，结合单词包等聚合，是一种常见的方法。这项工作的贡献是通过生成和组合三种不同面片分辨率的特征向量，并分析三种不同的组合方式，来扩展基于面片的最新方法。结果显示，三种多尺度方法中的一种都有所改善，而其他方法则导致得分下降。这为分析和讨论个别方法提供了动力。</li></ul></li><li>18、Reinforcing Generated Images via Meta-learning for One-Shot Fine-Grained Visual Recognition<ul><li>基于元学习的单次细粒度视觉识别增强生成图像</li><li>一次性细粒度视觉识别通常面临的问题是，新的细粒度类的训练示例很少。为了缓解这个问题，基于生成性对抗网络（GAN）的现成图像生成技术可以潜在地创建额外的训练图像。然而，这些生成的图像通常无助于提高单次细粒度识别的准确性。在本文中，我们提出了一个元学习框架，将生成的图像与原始图像相结合，从而生成的“混合”训练图像改进了一次性学习。具体来说，通过几个新类的训练实例来更新通用图像生成器，并提出了一种元图像增强网络（MetaIRNet）来进行一次细粒度识别和图像增强。我们的实验表明，在一次性细粒度图像分类基准上，与基线相比，一致性得到了改善。此外，我们的分析表明，与原始图像和GAN生成的图像相比，增强图像具有更多的多样性。</li></ul></li><li>19、Multiscale Analysis for Improving Texture Classification<ul><li>改进纹理分类的多尺度分析方法</li><li>来自图像的信息出现在多个不同的空间尺度上。图像金字塔多分辨率表示是一种有用的数据结构，用于在空间尺度的光谱上进行图像分析和操作。本文采用高斯-拉普拉斯金字塔分别处理纹理的不同空间频带。首先，我们为输入图像生成三个对应于高斯-拉普拉斯金字塔三级的图像，以捕捉内在细节。然后，我们使用仿生纹理描述符、信息论度量、灰度共生矩阵特征，将从灰度和彩色纹理图像中提取的特征聚集起来，并将统计特征分解为单个特征向量。与单独使用每个描述符不同，这种聚合旨在产生最大程度上表征纹理的特征，这可能会丢失一些相关的纹理信息并降低分类性能。在纹理和组织病理学图像数据集上的实验结果表明，与最先进的方法相比，该方法具有优势。这些发现强调了多尺度图像分析的重要性，并证实了上述描述符是互补的。</li></ul></li><li>20、Multiple EffNet/ResNet Architectures for Melanoma Classification<ul><li>用于黑色素瘤分类的多种EffNet/ResNet结构</li><li>黑色素瘤是最恶性的皮肤肿瘤，通常由正常的痣癌变，早期很难区分良恶性。因此，许多机器学习方法都试图进行辅助预测。然而，这些方法更多地关注疑似肿瘤的图像数据，侧重于提高图像分类的准确性，而忽视了患者层面的上下文信息在实际临床诊断中对疾病诊断的意义。为了更好地利用患者信息，提高诊断准确率，我们提出了一种新的基于EffNet和Resnet的黑色素瘤分类模型。我们的模型不仅使用相同的患者内的图像，而且还考虑患者级别的上下文信息，以更好的癌症预测。实验结果表明，该模型的ACC值为0.981。此外，我们注意到，该模型的总ROC值为0.976，这比以前的最先进方法要好。</li></ul></li></ul></div><footer class=post-footer><nav class=post-nav><a class=prev href=/post/%E7%BB%86%E7%B2%92%E5%BA%A6%E5%88%86%E7%B1%BB%E6%96%B9%E5%90%91%E8%B0%83%E7%A0%94/><i class=iconfont><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="18" height="18"><path d="M691.908486 949.511495l75.369571-89.491197c10.963703-12.998035 10.285251-32.864502-1.499144-44.378743L479.499795 515.267417l277.93508-310.326815c11.338233-12.190647 11.035334-32.285311-.638543-44.850487l-80.46666-86.564541c-11.680017-12.583596-30.356378-12.893658-41.662889-.716314L257.233596 494.235404c-11.332093 12.183484-11.041474 32.266891.657986 44.844348l80.46666 86.564541c1.772366 1.910513 3.706415 3.533476 5.750981 4.877077l306.620399 321.703933C662.505829 963.726242 680.945807 962.528973 691.908486 949.511495z"/></svg></i><span class="prev-text nav-default">细粒度分类方向调研</span>
<span class="prev-text nav-mobile">上一篇</span></a>
<a class=next href=/post/mobilenet/><span class="next-text nav-default">mobile net</span>
<span class="prev-text nav-mobile">下一篇</span>
<i class=iconfont><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="18" height="18"><path d="M332.091514 74.487481l-75.369571 89.491197c-10.963703 12.998035-10.285251 32.864502 1.499144 44.378743l286.278095 300.375162L266.565125 819.058374c-11.338233 12.190647-11.035334 32.285311.638543 44.850487l80.46666 86.564541c11.680017 12.583596 30.356378 12.893658 41.662889.716314l377.434212-421.426145c11.332093-12.183484 11.041474-32.266891-.657986-44.844348l-80.46666-86.564541c-1.772366-1.910513-3.706415-3.533476-5.750981-4.877077L373.270379 71.774697c-11.777231-11.500939-30.216186-10.304694-41.178865 2.712784z"/></svg></i></a></nav></footer></article></div></div></main><footer id=footer class=footer><div class=icon-links><a href=http://odyssey.halfbit.top/index.xml rel="noopener alternate" type=application/rss+xml class=iconfont title=rss target=_blank><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="30" height="30"><path d="M819.157333 1024C819.157333 574.592 449.408 204.8.0 204.8V0c561.706667.0 1024 462.293333 1024 1024H819.157333zM140.416 743.04a140.8 140.8.0 01140.501333 140.586667A140.928 140.928.0 01140.074667 1024C62.72 1024 0 961.109333.0 883.626667S62.933333 743.082667 140.416 743.04zM678.784 1024h-199.04c0-263.210667-216.533333-479.786667-479.744-479.786667v-199.04c372.352.0 678.784 306.517333 678.784 678.826667z"/></svg></a></div><div class=copyright><span class=power-by>Powered by <a class=hexo-link href=https://gohugo.io>Hugo</a></span>
<span class=division>|</span>
<span class=theme-info>Theme - <a class=theme-link href=https://github.com/xianmin/hugo-theme-jane>Jane</a></span>
<span class=copyright-year>&copy;
2022
<span class=heart><i class=iconfont><svg class="icon" viewBox="0 0 1025 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="14" height="14"><path d="M1000.1 247.9c-15.5-37.3-37.6-70.6-65.7-98.9-54.4-54.8-125.8-85-201-85-85.7.0-166 39-221.4 107.4C456.6 103 376.3 64 290.6 64c-75.1.0-146.5 30.4-201.1 85.6-28.2 28.5-50.4 61.9-65.8 99.3-16 38.8-24 79.9-23.6 122.2.7 91.7 40.1 177.2 108.1 234.8 3.1 2.6 6 5.1 8.9 7.8 14.9 13.4 58 52.8 112.6 102.7 93.5 85.5 209.9 191.9 257.5 234.2 7 6.1 15.8 9.5 24.9 9.5 9.2.0 18.1-3.4 24.9-9.5 34.5-30.7 105.8-95.9 181.4-165 74.2-67.8 150.9-138 195.8-178.2 69.5-57.9 109.6-144.4 109.9-237.3.1-42.5-8-83.6-24-122.2z" fill="#8a8a8a"/></svg></i></span><span class=author>momoka</span></span></div></footer><div class=back-to-top id=back-to-top><i class=iconfont><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="35" height="35"><path d="M510.866688 227.694839 95.449397 629.218702h235.761562L329.15309 958.01517h362.40389L691.55698 628.188232l241.942331-3.089361L510.866688 227.694839zM63.840492 63.962777h894.052392v131.813095H63.840492V63.962777zm0 0"/></svg></i></div></div><script type=text/javascript src=/lib/jquery/jquery-3.2.1.min.js></script>
<script type=text/javascript src=/lib/slideout/slideout-1.0.1.min.js></script>
<script type=text/javascript src=/js/main.638251f4230630f0335d8c6748e53a96f94b72670920b60c09a56fdc8bece214.js integrity="sha256-Y4JR9CMGMPAzXYxnSOU6lvlLcmcJILYMCaVv3Ivs4hQ=" crossorigin=anonymous></script>
<script type=text/javascript src=/js/load-photoswipe.js></script>
<script type=text/javascript src=/lib/photoswipe/photoswipe.min.js></script>
<script type=text/javascript src=/lib/photoswipe/photoswipe-ui-default.min.js></script></body></html>