<!doctype html><html lang=zh-cn itemscope itemtype=http://schema.org/WebPage><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><title>实验记录 - ODYSSEY</title><meta name=renderer content="webkit"><meta name=viewport content="width=device-width,initial-scale=1,user-scalable=yes"><meta name=MobileOptimized content="width"><meta name=HandheldFriendly content="true"><meta name=applicable-device content="pc,mobile"><meta name=theme-color content="#f8f5ec"><meta name=msapplication-navbutton-color content="#f8f5ec"><meta name=apple-mobile-web-app-capable content="yes"><meta name=apple-mobile-web-app-status-bar-style content="#f8f5ec"><meta name=mobile-web-app-capable content="yes"><meta name=author content="momo"><meta name=description content="公共数据集（肺炎） 新冠肺炎数据集 https://github.com/v7labs/covid-19-xray-dataset https://darwin.v7labs.com/v7-labs/covid-19-chest-x-ray-dataset 每个图像包含：肺炎类型的标签（病毒、细菌、真菌、健康/无） 亚齐老师之前的一篇： Multiscale Attention Guided Network for COVID-19 Diagnosis Using Chest X-ray Images https://arxiv.org/abs/2012.02278 数"><meta name=generator content="Hugo 0.111.3"><link rel=canonical href=http://odyssey.notbyai.space/post/10.12%E5%AE%9E%E9%AA%8C%E8%AE%B0%E5%BD%95/><link rel=icon href=/favicon.ico><link rel=stylesheet href=/sass/jane.min.d8d87b982993a745e5e7b6a6cbf257be8c3e82aab5e485f0908ad7e6c3501ab2.css integrity="sha256-2Nh7mCmTp0Xl57amy/JXvow+gqq15IXwkIrX5sNQGrI=" media=screen crossorigin=anonymous><meta property="og:title" content="实验记录"><meta property="og:description" content="公共数据集（肺炎） 新冠肺炎数据集 https://github.com/v7labs/covid-19-xray-dataset https://darwin.v7labs.com/v7-labs/covid-19-chest-x-ray-dataset 每个图像包含：肺炎类型的标签（病毒、细菌、真菌、健康/无） 亚齐老师之前的一篇： Multiscale Attention Guided Network for COVID-19 Diagnosis Using Chest X-ray Images https://arxiv.org/abs/2012.02278 数"><meta property="og:type" content="article"><meta property="og:url" content="http://odyssey.notbyai.space/post/10.12%E5%AE%9E%E9%AA%8C%E8%AE%B0%E5%BD%95/"><meta property="article:section" content="post"><meta property="article:published_time" content="2022-10-12T00:00:00+00:00"><meta property="article:modified_time" content="2022-10-12T00:00:00+00:00"><meta itemprop=name content="实验记录"><meta itemprop=description content="公共数据集（肺炎） 新冠肺炎数据集 https://github.com/v7labs/covid-19-xray-dataset https://darwin.v7labs.com/v7-labs/covid-19-chest-x-ray-dataset 每个图像包含：肺炎类型的标签（病毒、细菌、真菌、健康/无） 亚齐老师之前的一篇： Multiscale Attention Guided Network for COVID-19 Diagnosis Using Chest X-ray Images https://arxiv.org/abs/2012.02278 数"><meta itemprop=datePublished content="2022-10-12T00:00:00+00:00"><meta itemprop=dateModified content="2022-10-12T00:00:00+00:00"><meta itemprop=wordCount content="3653"><meta itemprop=keywords content><meta name=twitter:card content="summary"><meta name=twitter:title content="实验记录"><meta name=twitter:description content="公共数据集（肺炎） 新冠肺炎数据集 https://github.com/v7labs/covid-19-xray-dataset https://darwin.v7labs.com/v7-labs/covid-19-chest-x-ray-dataset 每个图像包含：肺炎类型的标签（病毒、细菌、真菌、健康/无） 亚齐老师之前的一篇： Multiscale Attention Guided Network for COVID-19 Diagnosis Using Chest X-ray Images https://arxiv.org/abs/2012.02278 数"><!--[if lte IE 9]><script src=https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js></script><![endif]--><!--[if lt IE 9]><script src=https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js></script>
<script src=https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js></script><![endif]--></head><body><div id=back-to-top></div><div id=mobile-navbar class=mobile-navbar><div class=mobile-header-logo><a href=/ class=logo>ODYSSEY</a></div><div class=mobile-navbar-icon><span></span>
<span></span>
<span></span></div></div><nav id=mobile-menu class="mobile-menu slideout-menu"><ul class=mobile-menu-list><li class=mobile-menu-item><a class=menu-item-link href=http://odyssey.notbyai.space/>Home</a></li><li class=mobile-menu-item><a class=menu-item-link href=http://odyssey.notbyai.space/post/>Archives</a></li><li class=mobile-menu-item><a class=menu-item-link href=http://odyssey.notbyai.space/categories/>Categories</a></li><li class=mobile-menu-item><a class=menu-item-link href=http://odyssey.notbyai.space/about/>About</a></li></ul></nav><link rel=stylesheet href=/lib/photoswipe/photoswipe.min.css><link rel=stylesheet href=/lib/photoswipe/default-skin/default-skin.min.css><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)"></button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><header id=header class=header><div class=logo-wrapper><a href=/ class=logo>ODYSSEY</a></div><nav class=site-navbar><ul id=menu class=menu><li class=menu-item><a class=menu-item-link href=http://odyssey.notbyai.space/>Home</a></li><li class=menu-item><a class=menu-item-link href=http://odyssey.notbyai.space/post/>Archives</a></li><li class=menu-item><a class=menu-item-link href=http://odyssey.notbyai.space/categories/>Categories</a></li><li class=menu-item><a class=menu-item-link href=http://odyssey.notbyai.space/about/>About</a></li></ul></nav></header><div id=mobile-panel><main id=main class="main bg-llight wallpaper"><div class=content-wrapper><div id=content class=content><article class=post><header class=post-header><h1 class=post-title>实验记录</h1><div class=post-meta><div class=post-meta-author>by
momo</div><div class=post-meta-time><time datetime=2022-10-12>2022-10-12</time></div><div class=post-meta__right><div class=post-meta-category><a href=http://odyssey.notbyai.space/categories/%E7%AC%94%E8%AE%B0/>笔记</a></div></div></div></header><div class=post-content><h2 id=公共数据集肺炎>公共数据集（肺炎）</h2><p>新冠肺炎数据集</p><p><a href=https://github.com/v7labs/covid-19-xray-dataset>https://github.com/v7labs/covid-19-xray-dataset</a></p><p><a href=https://darwin.v7labs.com/v7-labs/covid-19-chest-x-ray-dataset>https://darwin.v7labs.com/v7-labs/covid-19-chest-x-ray-dataset</a></p><p>每个图像包含：肺炎类型的标签（病毒、细菌、真菌、健康/无）</p><p>亚齐老师之前的一篇：</p><p>Multiscale Attention Guided Network for COVID-19 Diagnosis Using Chest X-ray Images</p><p><a href=https://arxiv.org/abs/2012.02278>https://arxiv.org/abs/2012.02278</a></p><p>数据集A：包括来自[15]的90个COVID-19和来自[17]的168个其他肺炎病例（新冠和非新冠的其他肺炎）</p><p>数据集B：从[47]和[17]中选出的，增加了健康这一类别（新冠，非新冠的其他肺炎，健康）</p><p>数据集C：作者主要操作的数据集，其中包括COVID-19和细粒度的肺炎分类（新冠、病毒、细菌、健康）</p><p>kaggle肺炎数据集</p><p><a href=https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia>https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia</a>（细粒度分类问题）</p><h2 id=odir-5k眼底>ODIR-5k（眼底）</h2><p>原比赛：https://odir2019.grand-challenge.org/</p><p>数据集构成：这是一个由5,000名病人组成的结构化眼科数据集。提供了**八种眼病类别的多标签图像级注释，包括糖尿病、青光眼、白内障、老年黄斑变性（AMD）、高血压、近视、正常和其他疾病。每个病人可能包含一个或多个疾病标签。**模型需要开发自动眼部疾病分类的方法。以左右眼的彩色眼底图像作为输入（可以使用其他提供的信息，如患者年龄、性别），目标是将患者分为八类。</p><table><thead><tr><th></th><th>训练集</th><th>测试集</th></tr></thead><tbody><tr><td>患者数量</td><td>3500</td><td>500</td></tr><tr><td>样本数量</td><td>7000</td><td>1000</td></tr></tbody></table><table><thead><tr><th>正常</th><th>糖尿病</th><th>青光眼</th><th>白内障</th><th>AMD</th><th>高血压</th><th>近视</th><th>其他疾病/异常</th></tr></thead><tbody><tr><td>1140</td><td>1128</td><td>215</td><td>212</td><td>164</td><td>103</td><td>174</td><td>979</td></tr></tbody></table><p>评估指标：参与者必须提交所有测试数据的八类分类结果。对于每个类别，分类概率（值从 0.0 到 1.0）表示被诊断为相应类别的患者的风险。 提交的内容根据三个指标进行评分：<a href="https://en.wikipedia.org/wiki/Cohen's_kappa">kappa score </a>、 <a href=https://en.wikipedia.org/wiki/F1_score>F-1 socre</a> 和 <a href=https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_the_curve>AUC value</a>。 阈值为 0.5。</p><p><img src=https://halfbit.oss-cn-hangzhou.aliyuncs.com/12791656585757_.pic.jpg alt></p><h2 id=下载地址>下载地址</h2><p>1.原比赛网址链接失效，kaggle下载（附带kaggle预处理版本的数据集）：https://www.kaggle.com/datasets/andrewmvd/ocular-disease-recognition-odir5k/code （预处理图片：只有训练图片，一共6392条记录，512大小，但是csv文件里面，对多标签图片只打了一个标签）</p><p>2.https://www.heywhale.com/mw/dataset/5e95e3ede7ec38002d0351f6</p><p>3.https://www.icode9.com/content-2-869077.html</p><p>已下载至论文积累/odir-5k文件夹。</p><h2 id=训练标注>训练标注</h2><p><img src=https://halfbit.oss-cn-hangzhou.aliyuncs.com/2022-07-215.03.28.png alt></p><p>3500个病人。包含患者年龄，患者性别信息。id为288的患者对应的左右眼图片分别是288_left、288_right。每个患者都有2张图片，没有缺失。描述关键词：中度非增殖性视网膜病变、轻度非增殖性视网膜病变、严重非增殖性视网膜病变、正常眼底图、视网膜激光手术后，中度非增殖性视网膜病变、视网膜激光手术后，糖尿病性视网膜病变、视网膜内微血管异常等，但是这个描述性关键词和八个病变的标签没有直接联系（左右眼不同的描述组合，可能标签是一样的）。有多标签、有单标签数据。每个标签的数量，是不均衡的（单标签里面，N和D的比较多；多标签里面，G和O就比较多）。一位患者对应两张图片，对应一组标签。两个norm，最后的标签是norm；一个norm，那么对病变图片的标签就是这个患者的标签；如果两只眼睛都是病变，那其实每张图片的标签是不确定的·。</p><h2 id=训练图片>训练图片</h2><p><img src=https://halfbit.oss-cn-hangzhou.aliyuncs.com/2022-07-215.10.28.png alt></p><p>数据分析 <a href=https://www.kaggle.com/code/ulafiliz/ocular-disease-detection-data-analysis>https://www.kaggle.com/code/ulafiliz/ocular-disease-detection-data-analysis</a> ：</p><p>1.对于给定数据集中的女性和男性的比较，男性的糖尿病视网膜病变略高，尽管男性眼底样本被诊断为 &ldquo;正常 &ldquo;的较多。
2.近视更可能发生在年轻男性身上。
3.大多数疾病的年龄分布是正常的。
4.女性比男性更有可能在早期被诊断出青光眼。</p><p><img src=https://halfbit.oss-cn-hangzhou.aliyuncs.com/2022-07-215.44.05.png alt></p><h2 id=odir-5k有关的论文>ODIR-5k有关的论文</h2><h4 id=classification-of-ocular-diseases-employing-attention-based-unilateral-and-bilateral-feature-weighting-and-fusion>CLASSIFICATION OF OCULAR DISEASES EMPLOYING ATTENTION-BASED UNILATERAL AND BILATERAL FEATURE WEIGHTING AND FUSION</h4><p>2020 IEEE 17th International Symposium on Biomedical Imaging (ISBI)</p><p>基于注意力的融合网络（AUBNet），将患者自动分类到相应的疾病类别中。具体来说，AUBNet由一个特征提取模块（FEM）、一个特征融合模块（FFM）和一个分类模块（CFM）组成。FEM从患者的双侧眼底照片中独立提取两个特征向量。通过FFM，进行两级特征加权和融合，以准备双眼的特征表示。最后，多标签分类由CFM进行。</p><p>这篇文章重在阐述它的FFM即特征融合这一部分，出发点是给左右眼的特征向量不同的权重，主要是在说明这个权重的计算是怎么计算的。这里的注意力就是用线性层（全连接层（权重、偏置）实现）。最终得到的向量，经过2个全连接层做分类。2048-512-8。最后用的loss函数是BCE二元交叉熵损失函数。</p><p>三个指标：kappa得分，f1得分，auc。最后加一个加权总分（平均）。</p><p>作者将数据集分成3部分，1167、1167和1166名患者。三折实验。</p><p>特征融合的部分，做了对比实验。相加、通道连接、乘法和提出的进行对比。特征提取器分别使用resnet18、34、50、101。训练的时候，图像resize成512*512；训练过程中，random crop成448大小。测试时候用的是center crop。用的SGD优化器。学习率策略：The poly learning rate decay policy is used with an initial learning rate of 0.007, power of 0.9, and epoch of 50.</p><p><img src=https://halfbit.oss-cn-hangzhou.aliyuncs.com/2022-07-204.12.22.png alt></p><p>第二个消融实验。只有一次注意力融合：把中间紫色部分（只做一阶融合）的向量，用于分类。接CFM。只有两次的融合：用计算出的beta权重和最前面的红灰向量做加权相加。两个融合结合：本文最早提出的方法。发现最后一种效果是最好的。</p><p>为了验证注意力的权重是不是正确，分类标签是在病人层面上给出的，个别眼睛有诊断关键词。根据这些关键词，我们只能区分眼睛是否受到影响，而不能确定具体的眼部疾病。为了简化结果的解释，我们将200个只有一只眼睛受影响的病人的学习权重可视化。总的来说，患病的眼睛得到的权重更大。而平均权重也存在明显的差异——患病的眼睛权重比正常眼睛的权重要高。</p><p><img src=https://halfbit.oss-cn-hangzhou.aliyuncs.com/2022-07-204.38.34.png alt></p><p>作者对CFM这个模块没有详细说，sigmoid+bceloss。https://zhuanlan.zhihu.com/p/500347063</p><p>论文无代码。</p><h4 id=cct-net-category-invariant-cross-domain-transfer-for-medical-single-to-multiple-disease-diagnosis>CCT-Net: Category-Invariant Cross-Domain Transfer for Medical Single-to-Multiple Disease Diagnosis</h4><p>2021 ICCV</p><p>类别不变的领域迁移。单疾病诊断-多疾病诊断</p><p>1.将糖尿病视网膜病变扩展到识别多种眼部疾病。2.将胶质瘤识别扩展到其他脑肿瘤的诊断。</p><p>从带有精细注释的单一疾病诊断中学习到的知识，可以被转移到改善没有注释的多种相关疾病的诊断中。源领域需要有像素级别的标注，并且是单一标签。然后目标域是没有标注的，多标签。只知道图像级的疾病类别。</p><p><img src=https://halfbit.oss-cn-hangzhou.aliyuncs.com/2022-07-205.53.11.png alt></p><p>本文重点：1. 设计了一个特定领域的任务学习模块，以学习领域的变量特征，同时保留两个领域之间的疾病差异。提出了一种CWP全局汇集方法，以获得比其他全局汇集操作更好的类激活图（CAMs）。2. 以不同类别的粗略热图为条件，我们提出了CIFR区块来构建CCTNet，以定位相应疾病的更多鉴别性区域。类别不变的特征使其能够从源域转移到目标域。此外，这种重新定义的特征也有助于提高最终分类的性能。3.实验评估是在两个流行的医学成像任务中进行的。首先，我们将眼底图像的DR诊断扩展到多种眼部疾病的诊断，如青光眼和高血压。第二，利用脑部MRI扫描的胶质瘤分割来改善其他肿瘤的分割和分类性能，如脑膜瘤和垂体瘤。实验结果证明了我们方法的有效性。</p><p>本文任务：（从overall开始看），作者的目标是不光光提升目标领域对于图像类别的诊断，还有疾病的定位。</p><p><img src=https://halfbit.oss-cn-hangzhou.aliyuncs.com/2022-07-206.07.10.png alt></p><p>DSE （Domain specific encoder）：</p><p>两个领域共享卷积（Conv）参数，以约束编码器学习领域不变的表征。领域特定批量归一化（BN）来加强对领域不变特征的学习。为了构建DSE，我们采用DenseNet-121[24]作为骨干。在每个Conv层之后，不同领域的BN层被分别学习。</p><p>除了获得不同疾病的初步分类结果外，DSE还能计算不同类别的粗略热图。在图像分类任务中，仅使用图像级标签的弱监督方法[8, 50]通常采用类激活图（CAM）[55]来计算定位每个类别的粗略热图。一个特定类别的CAM表明网络用来识别该类别的鉴别性图像区域，并可用于解释网络做出的预测决定。这种定位能力是由基本全局平均/最大集合（GAP/GMP）层实现的。虽然GAP和GMP已被广泛使用，但它们是不可训练的，而且CAM可能无法定位最具有鉴别力的区域。Log-Sum-Exp（LSE）池化[43]引入了一个超参数γ，作为最大池化和平均池化之间的一个可调节选项。然而，LSE池仍然是不可优化的，并且存在过流或欠流问题。</p><p>在这项工作中，我们提出了一种可训练的CWP全局池化方法，以更好的定位性能增强原始CAM。源域和目标域的任务学习。尽管最初的基于CWP的CAM已经摒弃了大面积的不相关区域来区分正确的疾病，但其粗略的热图仍然包含一些来自噪声或错误分类的干扰信息。在这项工作中，我们的目标是将这些粗略的热图重新细化为细化的像素级预测，以划定更多的鉴别区域，并将这种重新细化的能力从源域转移到目标域。请注意，CAM可能不是最好的弱监督定位方法[8]，但这不是这项工作的主要关切。我们将在今后的工作中专门研究这一点，以增强CCT-Net的功能。</p><p>CCT-Net堆叠了多组CIFR块。</p><p>分类结果如下（高于上文）</p><p>论文无代码。</p><p><img src=https://halfbit.oss-cn-hangzhou.aliyuncs.com/2022-07-219.57.25.png alt></p><p>其他论文</p><p><a href="https://www.x-mol.com/paper/search/q?option=odir%E6%95%B0%E6%8D%AE%E9%9B%86">https://www.x-mol.com/paper/search/q?option=odir%E6%95%B0%E6%8D%AE%E9%9B%86</a></p><p><img src=https://halfbit.oss-cn-hangzhou.aliyuncs.com/2022-10-134.53.42.png alt></p><p><img src=https://halfbit.oss-cn-hangzhou.aliyuncs.com/2022-10-134.51.40.png alt></p><p><img src=https://halfbit.oss-cn-hangzhou.aliyuncs.com/2022-10-134.51.59.png alt></p><p><strong><a href=https://www.x-mol.com/paperRedirect/1466480909038288896>基于R-CNN+LSTM模型和NCAR特征选择的眼底图像眼科疾病检测的有效且稳健的方法</a></strong></p><p>Optimized convolution neural network based multiple eye disease detection</p><p><img src=https://halfbit.oss-cn-hangzhou.aliyuncs.com/2022-10-134.52.03.png alt></p></div><footer class=post-footer><nav class=post-nav><a class=prev href=/post/%E8%B7%9F%E7%9D%80chatgpt%E5%AD%A6%E4%B9%A0aigc%E4%B8%80/><i class=iconfont><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="18" height="18"><path d="M691.908486 949.511495l75.369571-89.491197c10.963703-12.998035 10.285251-32.864502-1.499144-44.378743L479.499795 515.267417l277.93508-310.326815c11.338233-12.190647 11.035334-32.285311-.638543-44.850487l-80.46666-86.564541c-11.680017-12.583596-30.356378-12.893658-41.662889-.716314L257.233596 494.235404c-11.332093 12.183484-11.041474 32.266891.657986 44.844348l80.46666 86.564541c1.772366 1.910513 3.706415 3.533476 5.750981 4.877077l306.620399 321.703933C662.505829 963.726242 680.945807 962.528973 691.908486 949.511495z"/></svg></i><span class="prev-text nav-default">跟着ChatGPT学习AIGC（二）</span>
<span class="prev-text nav-mobile">上一篇</span></a>
<a class=next href=/post/luna%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/><span class="next-text nav-default">luna论文笔记</span>
<span class="prev-text nav-mobile">下一篇</span>
<i class=iconfont><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="18" height="18"><path d="M332.091514 74.487481l-75.369571 89.491197c-10.963703 12.998035-10.285251 32.864502 1.499144 44.378743l286.278095 300.375162L266.565125 819.058374c-11.338233 12.190647-11.035334 32.285311.638543 44.850487l80.46666 86.564541c11.680017 12.583596 30.356378 12.893658 41.662889.716314l377.434212-421.426145c11.332093-12.183484 11.041474-32.266891-.657986-44.844348l-80.46666-86.564541c-1.772366-1.910513-3.706415-3.533476-5.750981-4.877077L373.270379 71.774697c-11.777231-11.500939-30.216186-10.304694-41.178865 2.712784z"/></svg></i></a></nav></footer></article></div><nav class=toc id=toc><div class=toc-title>文章目录</div><div class="toc-content custom-scrollbar"><nav id=TableOfContents><ul><li><a href=#公共数据集肺炎>公共数据集（肺炎）</a></li><li><a href=#odir-5k眼底>ODIR-5k（眼底）</a></li><li><a href=#下载地址>下载地址</a></li><li><a href=#训练标注>训练标注</a></li><li><a href=#训练图片>训练图片</a></li><li><a href=#odir-5k有关的论文>ODIR-5k有关的论文</a><ul><li></li></ul></li></ul></nav></div></nav></div></main><footer id=footer class=footer><div class=icon-links><a href=http://odyssey.notbyai.space/index.xml rel="noopener alternate" type=application/rss+xml class=iconfont title=rss target=_blank><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="30" height="30"><path d="M819.157333 1024C819.157333 574.592 449.408 204.8.0 204.8V0c561.706667.0 1024 462.293333 1024 1024H819.157333zM140.416 743.04a140.8 140.8.0 01140.501333 140.586667A140.928 140.928.0 01140.074667 1024C62.72 1024 0 961.109333.0 883.626667S62.933333 743.082667 140.416 743.04zM678.784 1024h-199.04c0-263.210667-216.533333-479.786667-479.744-479.786667v-199.04c372.352.0 678.784 306.517333 678.784 678.826667z"/></svg></a></div><div class=copyright><span class=power-by>Powered by <a class=hexo-link href=https://gohugo.io>Hugo</a></span>
<span class=division>|</span>
<span class=theme-info>Theme - <a class=theme-link href=https://github.com/xianmin/hugo-theme-jane>Jane</a></span>
<span class=copyright-year>&copy;
2022 -
2023
<span class=heart><i class=iconfont><svg class="icon" viewBox="0 0 1025 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="14" height="14"><path d="M1000.1 247.9c-15.5-37.3-37.6-70.6-65.7-98.9-54.4-54.8-125.8-85-201-85-85.7.0-166 39-221.4 107.4C456.6 103 376.3 64 290.6 64c-75.1.0-146.5 30.4-201.1 85.6-28.2 28.5-50.4 61.9-65.8 99.3-16 38.8-24 79.9-23.6 122.2.7 91.7 40.1 177.2 108.1 234.8 3.1 2.6 6 5.1 8.9 7.8 14.9 13.4 58 52.8 112.6 102.7 93.5 85.5 209.9 191.9 257.5 234.2 7 6.1 15.8 9.5 24.9 9.5 9.2.0 18.1-3.4 24.9-9.5 34.5-30.7 105.8-95.9 181.4-165 74.2-67.8 150.9-138 195.8-178.2 69.5-57.9 109.6-144.4 109.9-237.3.1-42.5-8-83.6-24-122.2z" fill="#8a8a8a"/></svg></i></span><span class=author>momoka</span></span></div></footer><div class=button__back-to-top><a href=#back-to-top><i class=iconfont><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="35" height="35"><path d="M510.866688 227.694839 95.449397 629.218702h235.761562L329.15309 958.01517h362.40389L691.55698 628.188232l241.942331-3.089361L510.866688 227.694839zM63.840492 63.962777h894.052392v131.813095H63.840492V63.962777zm0 0"/></svg></i></a></div></div><script type=text/javascript src=/lib/jquery/jquery-3.2.1.min.js></script>
<script type=text/javascript src=/lib/slideout/slideout-1.0.1.min.js></script>
<script type=text/javascript src=/js/main.b1aac56ececadf3a3aba77122c8081efa208813d5b2b8e5874ae9ea16c14f8c1.js integrity="sha256-sarFbs7K3zo6uncSLICB76IIgT1bK45YdK6eoWwU+ME=" crossorigin=anonymous></script>
<script type=text/javascript src=/lib/photoswipe/photoswipe.min.js></script>
<script type=text/javascript src=/lib/photoswipe/photoswipe-ui-default.min.js></script></body></html>