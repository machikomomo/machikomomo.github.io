<!doctype html><html lang=zh-cn itemscope itemtype=http://schema.org/WebPage><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><title>SimCLR论文笔记 - ODYSSEY</title><meta name=renderer content="webkit"><meta name=viewport content="width=device-width,initial-scale=1,user-scalable=yes"><meta name=MobileOptimized content="width"><meta name=HandheldFriendly content="true"><meta name=applicable-device content="pc,mobile"><meta name=theme-color content="#f8f5ec"><meta name=msapplication-navbutton-color content="#f8f5ec"><meta name=apple-mobile-web-app-capable content="yes"><meta name=apple-mobile-web-app-status-bar-style content="#f8f5ec"><meta name=mobile-web-app-capable content="yes"><meta name=author content="momo"><meta name=description content="我的启发 了解了这个基于对比学习的自监督框架。它的结构比较简单，也容易实现。在csdn上找了pytorch的实现版本（github上也有，但是"><meta name=generator content="Hugo 0.99.1"><link rel=canonical href=http://odyssey.halfbit.top/post/simclr%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/><link rel=icon href=/favicon.ico><link rel=stylesheet href=/sass/jane.min.fa4b2b9f31b5c6d0b683db81157a9226e17b06e61911791ab547242a4a0556f2.css integrity="sha256-+ksrnzG1xtC2g9uBFXqSJuF7BuYZEXkatUckKkoFVvI=" media=screen crossorigin=anonymous><meta property="og:title" content="SimCLR论文笔记"><meta property="og:description" content="我的启发 了解了这个基于对比学习的自监督框架。它的结构比较简单，也容易实现。在csdn上找了pytorch的实现版本（github上也有，但是"><meta property="og:type" content="article"><meta property="og:url" content="http://odyssey.halfbit.top/post/simclr%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"><meta property="article:section" content="post"><meta property="article:published_time" content="2022-05-07T00:00:00+00:00"><meta property="article:modified_time" content="2022-05-07T00:00:00+00:00"><meta itemprop=name content="SimCLR论文笔记"><meta itemprop=description content="我的启发 了解了这个基于对比学习的自监督框架。它的结构比较简单，也容易实现。在csdn上找了pytorch的实现版本（github上也有，但是"><meta itemprop=datePublished content="2022-05-07T00:00:00+00:00"><meta itemprop=dateModified content="2022-05-07T00:00:00+00:00"><meta itemprop=wordCount content="2009"><meta itemprop=keywords content><meta name=twitter:card content="summary"><meta name=twitter:title content="SimCLR论文笔记"><meta name=twitter:description content="我的启发 了解了这个基于对比学习的自监督框架。它的结构比较简单，也容易实现。在csdn上找了pytorch的实现版本（github上也有，但是"><!--[if lte IE 9]><script src=https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js></script><![endif]--><!--[if lt IE 9]><script src=https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js></script>
<script src=https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js></script><![endif]--></head><body><div id=mobile-navbar class=mobile-navbar><div class=mobile-header-logo><a href=/ class=logo>ODYSSEY</a></div><div class=mobile-navbar-icon><span></span>
<span></span>
<span></span></div></div><nav id=mobile-menu class="mobile-menu slideout-menu"><ul class=mobile-menu-list><li class=mobile-menu-item><a class=menu-item-link href=http://odyssey.halfbit.top/>Home</a></li><li class=mobile-menu-item><a class=menu-item-link href=http://odyssey.halfbit.top/post/>Archives</a></li><li class=mobile-menu-item><a class=menu-item-link href=http://odyssey.halfbit.top/categories/>Categories</a></li><li class=mobile-menu-item><a class=menu-item-link href=http://odyssey.halfbit.top/about/>About</a></li></ul></nav><link rel=stylesheet href=/lib/photoswipe/photoswipe.min.css><link rel=stylesheet href=/lib/photoswipe/default-skin/default-skin.min.css><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)"></button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><header id=header class="header container"><div class=logo-wrapper><a href=/ class=logo>ODYSSEY</a></div><nav class=site-navbar><ul id=menu class=menu><li class=menu-item><a class=menu-item-link href=http://odyssey.halfbit.top/>Home</a></li><li class=menu-item><a class=menu-item-link href=http://odyssey.halfbit.top/post/>Archives</a></li><li class=menu-item><a class=menu-item-link href=http://odyssey.halfbit.top/categories/>Categories</a></li><li class=menu-item><a class=menu-item-link href=http://odyssey.halfbit.top/about/>About</a></li></ul></nav></header><div id=mobile-panel><main id=main class="main bg-llight"><div class=content-wrapper><div id=content class="content container"><article class="post bg-white"><header class=post-header><h1 class=post-title>SimCLR论文笔记</h1><div class=post-meta><time datetime=2022-05-07 class=post-time>2022-05-07</time><div class=post-category><a href=http://odyssey.halfbit.top/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/>论文笔记</a>
<a href=http://odyssey.halfbit.top/categories/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F%E5%88%86%E6%9E%90/>医学图像分析</a>
<a href=http://odyssey.halfbit.top/categories/icml/>ICML</a></div></div></header><div class=post-toc id=post-toc><h2 class=post-toc-title>文章目录</h2><div class=post-toc-content><nav id=TableOfContents><ul><li><a href=#我的启发>我的启发</a></li><li><a href=#引用>引用</a></li><li><a href=#博客>博客</a></li><li><a href=#简介>简介</a></li><li><a href=#contrastive-loss>contrastive loss</a></li><li><a href=#nt-xent>NT-Xent</a></li><li><a href=#如何评价representation的好坏>如何评价representation的好坏</a></li><li><a href=#三个重要观点>三个重要观点</a></li><li><a href=#代码pytorch>代码（pytorch）</a></li></ul></nav></div></div><div class=post-content><h2 id=我的启发>我的启发</h2><p>了解了这个基于对比学习的自监督框架。它的结构比较简单，也容易实现。在csdn上找了pytorch的实现版本（github上也有，但是代码有些看不懂的，晚点对比看看区别）。它的结构分成两个部分。第一阶段是用没有标签的数据完成自监督预训练，第二阶段是用带有标签的数据进行监督学习，完成整个网络框架。缺点就是batch_size真的很大，需要非常充足的算力。</p><h2 id=引用>引用</h2><p>A Simple Framework for Contrastive Learning of Visual Representations,</p><p>ICML, 2020,</p><p><a href=https://arxiv.org/abs/2002.05709>https://arxiv.org/abs/2002.05709</a>.</p><h2 id=博客>博客</h2><p>已经有其他很多博客写过了。我觉得写得也很清楚。这里是我看过的几篇。</p><p><a href=https://zhuanlan.zhihu.com/p/258958247>https://zhuanlan.zhihu.com/p/258958247</a></p><p><a href=https://zhuanlan.zhihu.com/p/197802321>https://zhuanlan.zhihu.com/p/197802321</a></p><h2 id=简介>简介</h2><p>如下图，对一个batch中的每一张图片x，都进行两次数据增强。分别得到xi，xj。通过同一个网络进行特征提取（如resnet50），得到hi，hj（文中称为representation）；然后对hi，hj进行非线性变换（投影），文中用了mlp，得到z。用z来进行contrastive loss的计算。</p><p>优化loss。</p><p>以上整个过程是无监督的，使用没有标签的数据。</p><p>优化迭代结束，对应的representation，就拿来用于处理下游任务。比如分类任务，就在上一阶段的网络架构上，增加一个简单的全连接层，固定全连接层之前的参数不动，选用一些带有标签的数据，进行监督训练。</p><p>要注意的是尽管图中加了一层g层（mlp），但是这么做的原因仅仅是辅助，拿计算得到的z来进行loss计算。这样做的效果比直接使用h去进行loss计算结果要好。最终目的是得到好的representation用于下游任务。</p><p><img src=https://halfbit.oss-cn-hangzhou.aliyuncs.com/framework1.png alt></p><h2 id=contrastive-loss>contrastive loss</h2><p>下图中#pairwise similarity对照上图，指的是同一张图片经过两种数据增强得到的两个结果。计算相似度。这个相似度越小越好。</p><p>当i和除了i（本身）、j（来自于同一张图片）以外的其他图片进行相似度计算（余弦距离）的时候，应当是越大越好。</p><p>对照下图中的define l(i,j)，分母应该是用来做归一化，同时loss会朝着分子越小，分母越大的趋势优化。</p><p>即同一个数据增强以后的图片越相似（类内距离减小）；不同图片增强以后不相似（类间距离增大）。</p><p><img src=https://halfbit.oss-cn-hangzhou.aliyuncs.com/gongshi1.png alt></p><p>搬一个别人的解释。假设输入1是dog、输入2是cat，输入3是tree。经过数据增强以后分别得到1a，1b。2a，2b。3a，3b。</p><p>“以楼主的1a,1b为例，分子是（1a,1b）的相似度，分母应该是【（1a,1b）+（1a,2a）+（1a,2b）+（1a,3a）+（1a,3b）】”。</p><p>（以上都是看别人的博客，感觉还是乱乱的，自己枚举了一下。假设有3个输入，也就是N=3。k=1，2，3。</p><p>x1经过数据增强，记为x1，x2.</p><p>x2经过数据增强，记为x3，x4.</p><p>x3经过数据增强，记为x5，x6.</p><p>取第二组数据为例，i=3，j=4.计算l(3,4).分子是<strong>s(3,4)</strong>.分母是<strong>s(3,1)+s(3,2)+s(3,4)+s(3,5)+s(3,6)</strong></p><p>最终的contrasive loss的定义是如图的L.</p><p>也就是N=3时：1/6 *（l(1,2)+l(2,1)+l(3,4)+l(4,3)+l(5,6)+l(6,5))</p><p>好吧……</p><h2 id=nt-xent>NT-Xent</h2><p>补充一下。作者的contrastive loss是基于NT-Xent得到的一个总的优化目标。NT-Xent非原创。总结：一个batch N 个samples，因为有两条分支所以增强后就能得到2N个samples。i，j 是positive pair（正样本对），剩下的2N-2是negative pair（负样本对）。</p><p><img src=https://halfbit.oss-cn-hangzhou.aliyuncs.com/gongshi2.png alt></p><p>loss 中含有一个温度参数<img src="https://www.zhihu.com/equation?tex=%5Ctau" alt=[公式]>，可以用来控制loss对负样本对的敏感程度。</p><p><img src=https://pic2.zhimg.com/80/v2-5696af8c45b95d1c5e8fb9614917a79d_1440w.jpg alt=img></p><p>0、图的横轴是负样本对之间的相似性，相似性越趋近于1，代表这个样本对是 hard case。竖轴是在不同的<img src="https://www.zhihu.com/equation?tex=%5Ctau" alt=[公式]>取值下负样本对所获取的惩罚。</p><p>1、<img src="https://www.zhihu.com/equation?tex=%5Ctau" alt=[公式]>越小，loss会倾向于给相似性较大的负样本较大的惩罚，对hard case会越敏感。</p><p>2、<img src="https://www.zhihu.com/equation?tex=%5Ctau" alt=[公式]>越大，loss会倾向于给相似性较大的负样本较小的惩罚，对hard case会越不敏感。</p><p>3、相似性较大的负样本，也就是 hard case。比如原图为一直狗A，那么另外一只狗B的图像或者一只狼的图像C相对A来说就是hard case；而一个人D或者建筑E的图像相对于A来说就是easy case。</p><p>4、<img src="https://www.zhihu.com/equation?tex=%5Ctau" alt=[公式]>需要根据不同的任务背景去做取舍超参，SimCLR原作实验结果 <img src="https://www.zhihu.com/equation?tex=%5Ctau" alt=[公式]>为0.25时取得最优结果。</p><h2 id=如何评价representation的好坏>如何评价representation的好坏</h2><p>通过固定特征提取器 <img src="https://www.zhihu.com/equation?tex=f" alt=[公式]> ，然后加上一个线性分类器输出one-hot。通过监督学习（有label）训练线性分类器，得到的精度作为评估<img src="https://www.zhihu.com/equation?tex=f" alt=[公式]>提取特征能力的指标。</p><h2 id=三个重要观点>三个重要观点</h2><p>(1) Data augmentation is crucial to UCL；</p><p>单纯的图片裁剪没什么效果。加上了color distortion才有显著效果。左边8张图，只有裁剪。看直方图就能分辨是否是一张图片裁剪出来的。右边8张图，加上color distortion。</p><p><img src=https://miro.medium.com/max/1400/1*rujTYcDmDRxxpeTT_CmZAw.png alt=img></p><p>(2) More variables and training steps give better performance；</p><p>模型大，参数多，增加训练时间，效果好。</p><p>(3) Large batch size benefit SimCLR。</p><p>batch_size越大越好。好贵。</p><p><img src=https://miro.medium.com/max/1400/1*yrzj_3xxzWNBWBp8JjgNJw.png alt=img></p><h2 id=代码pytorch>代码（pytorch）</h2><p><a href=https://github.com/sthalles/SimCLR>https://github.com/sthalles/SimCLR</a></p><p><a href=https://github.com/Spijkervet/SimCLR>https://github.com/Spijkervet/SimCLR</a></p></div><footer class=post-footer><nav class=post-nav><a class=prev href=/post/%E5%9F%BA%E4%BA%8E%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E7%9A%84%E8%AE%A1%E7%AE%97%E6%80%A7%E7%BB%84%E7%BB%87%E7%97%85%E7%90%86%E5%AD%A6%E9%A2%84%E6%B5%8B%E7%99%8C%E7%97%87%E9%A9%B1%E5%8A%A8%E5%9F%BA%E5%9B%A0%E7%9A%84%E5%B7%AE%E5%BC%82%E6%80%A7%E8%A1%A8%E8%BE%BE/><i class=iconfont><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="18" height="18"><path d="M691.908486 949.511495l75.369571-89.491197c10.963703-12.998035 10.285251-32.864502-1.499144-44.378743L479.499795 515.267417l277.93508-310.326815c11.338233-12.190647 11.035334-32.285311-.638543-44.850487l-80.46666-86.564541c-11.680017-12.583596-30.356378-12.893658-41.662889-.716314L257.233596 494.235404c-11.332093 12.183484-11.041474 32.266891.657986 44.844348l80.46666 86.564541c1.772366 1.910513 3.706415 3.533476 5.750981 4.877077l306.620399 321.703933C662.505829 963.726242 680.945807 962.528973 691.908486 949.511495z"/></svg></i><span class="prev-text nav-default">基于对比学习的计算性组织病理学预测癌症驱动基因的差异性表达</span>
<span class="prev-text nav-mobile">上一篇</span></a>
<a class=next href=/post/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9C%A8%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F%E5%88%86%E6%9E%90%E4%B8%AD%E7%9A%84%E6%9C%80%E6%96%B0%E8%BF%9B%E5%B1%95%E5%92%8C%E4%B8%B4%E5%BA%8A%E5%BA%94%E7%94%A8/><span class="next-text nav-default">深度学习在医学图像分析中的最新进展和临床应用</span>
<span class="prev-text nav-mobile">下一篇</span>
<i class=iconfont><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="18" height="18"><path d="M332.091514 74.487481l-75.369571 89.491197c-10.963703 12.998035-10.285251 32.864502 1.499144 44.378743l286.278095 300.375162L266.565125 819.058374c-11.338233 12.190647-11.035334 32.285311.638543 44.850487l80.46666 86.564541c11.680017 12.583596 30.356378 12.893658 41.662889.716314l377.434212-421.426145c11.332093-12.183484 11.041474-32.266891-.657986-44.844348l-80.46666-86.564541c-1.772366-1.910513-3.706415-3.533476-5.750981-4.877077L373.270379 71.774697c-11.777231-11.500939-30.216186-10.304694-41.178865 2.712784z"/></svg></i></a></nav></footer></article></div></div></main><footer id=footer class=footer><div class=icon-links><a href=http://odyssey.halfbit.top/index.xml rel="noopener alternate" type=application/rss+xml class=iconfont title=rss target=_blank><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="30" height="30"><path d="M819.157333 1024C819.157333 574.592 449.408 204.8.0 204.8V0c561.706667.0 1024 462.293333 1024 1024H819.157333zM140.416 743.04a140.8 140.8.0 01140.501333 140.586667A140.928 140.928.0 01140.074667 1024C62.72 1024 0 961.109333.0 883.626667S62.933333 743.082667 140.416 743.04zM678.784 1024h-199.04c0-263.210667-216.533333-479.786667-479.744-479.786667v-199.04c372.352.0 678.784 306.517333 678.784 678.826667z"/></svg></a></div><div class=copyright><span class=power-by>Powered by <a class=hexo-link href=https://gohugo.io>Hugo</a></span>
<span class=division>|</span>
<span class=theme-info>Theme - <a class=theme-link href=https://github.com/xianmin/hugo-theme-jane>Jane</a></span>
<span class=copyright-year>&copy;
2022
<span class=heart><i class=iconfont><svg class="icon" viewBox="0 0 1025 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="14" height="14"><path d="M1000.1 247.9c-15.5-37.3-37.6-70.6-65.7-98.9-54.4-54.8-125.8-85-201-85-85.7.0-166 39-221.4 107.4C456.6 103 376.3 64 290.6 64c-75.1.0-146.5 30.4-201.1 85.6-28.2 28.5-50.4 61.9-65.8 99.3-16 38.8-24 79.9-23.6 122.2.7 91.7 40.1 177.2 108.1 234.8 3.1 2.6 6 5.1 8.9 7.8 14.9 13.4 58 52.8 112.6 102.7 93.5 85.5 209.9 191.9 257.5 234.2 7 6.1 15.8 9.5 24.9 9.5 9.2.0 18.1-3.4 24.9-9.5 34.5-30.7 105.8-95.9 181.4-165 74.2-67.8 150.9-138 195.8-178.2 69.5-57.9 109.6-144.4 109.9-237.3.1-42.5-8-83.6-24-122.2z" fill="#8a8a8a"/></svg></i></span><span class=author>momoka</span></span></div></footer><div class=back-to-top id=back-to-top><i class=iconfont><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="35" height="35"><path d="M510.866688 227.694839 95.449397 629.218702h235.761562L329.15309 958.01517h362.40389L691.55698 628.188232l241.942331-3.089361L510.866688 227.694839zM63.840492 63.962777h894.052392v131.813095H63.840492V63.962777zm0 0"/></svg></i></div></div><script type=text/javascript src=/lib/jquery/jquery-3.2.1.min.js></script>
<script type=text/javascript src=/lib/slideout/slideout-1.0.1.min.js></script>
<script type=text/javascript src=/js/main.638251f4230630f0335d8c6748e53a96f94b72670920b60c09a56fdc8bece214.js integrity="sha256-Y4JR9CMGMPAzXYxnSOU6lvlLcmcJILYMCaVv3Ivs4hQ=" crossorigin=anonymous></script>
<script type=text/javascript src=/js/load-photoswipe.js></script>
<script type=text/javascript src=/lib/photoswipe/photoswipe.min.js></script>
<script type=text/javascript src=/lib/photoswipe/photoswipe-ui-default.min.js></script></body></html>