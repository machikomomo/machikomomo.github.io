<!doctype html><html lang=zh-cn itemscope itemtype=http://schema.org/WebPage><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><title>odor-5k-0 - ODYSSEY</title><meta name=renderer content="webkit"><meta name=viewport content="width=device-width,initial-scale=1,user-scalable=yes"><meta name=MobileOptimized content="width"><meta name=HandheldFriendly content="true"><meta name=applicable-device content="pc,mobile"><meta name=theme-color content="#f8f5ec"><meta name=msapplication-navbutton-color content="#f8f5ec"><meta name=apple-mobile-web-app-capable content="yes"><meta name=apple-mobile-web-app-status-bar-style content="#f8f5ec"><meta name=mobile-web-app-capable content="yes"><meta name=author content="momo"><meta name=description content="AAAI2022 Inferring Prototypes for Multi-Label Few-Shot Image Classification with Word Vector Guided Attention （1.标签转为词向量） 多标签图像分类（ML-IC）+少量图像分类（FSIC）=多标签少量图像分类模型（ML-FSI"><meta name=generator content="Hugo 0.102.3"><link rel=canonical href=http://odyssey.halfbit.top/post/pre/><link rel=icon href=/favicon.ico><link rel=stylesheet href=/sass/jane.min.fa4b2b9f31b5c6d0b683db81157a9226e17b06e61911791ab547242a4a0556f2.css integrity="sha256-+ksrnzG1xtC2g9uBFXqSJuF7BuYZEXkatUckKkoFVvI=" media=screen crossorigin=anonymous><meta property="og:title" content="odor-5k-0"><meta property="og:description" content="AAAI2022 Inferring Prototypes for Multi-Label Few-Shot Image Classification with Word Vector Guided Attention （1.标签转为词向量） 多标签图像分类（ML-IC）+少量图像分类（FSIC）=多标签少量图像分类模型（ML-FSI"><meta property="og:type" content="article"><meta property="og:url" content="http://odyssey.halfbit.top/post/pre/"><meta property="article:section" content="post"><meta property="article:published_time" content="2022-07-27T00:00:00+00:00"><meta property="article:modified_time" content="2022-07-27T00:00:00+00:00"><meta itemprop=name content="odor-5k-0"><meta itemprop=description content="AAAI2022 Inferring Prototypes for Multi-Label Few-Shot Image Classification with Word Vector Guided Attention （1.标签转为词向量） 多标签图像分类（ML-IC）+少量图像分类（FSIC）=多标签少量图像分类模型（ML-FSI"><meta itemprop=datePublished content="2022-07-27T00:00:00+00:00"><meta itemprop=dateModified content="2022-07-27T00:00:00+00:00"><meta itemprop=wordCount content="3283"><meta itemprop=keywords content><meta name=twitter:card content="summary"><meta name=twitter:title content="odor-5k-0"><meta name=twitter:description content="AAAI2022 Inferring Prototypes for Multi-Label Few-Shot Image Classification with Word Vector Guided Attention （1.标签转为词向量） 多标签图像分类（ML-IC）+少量图像分类（FSIC）=多标签少量图像分类模型（ML-FSI"><!--[if lte IE 9]><script src=https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js></script><![endif]--><!--[if lt IE 9]><script src=https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js></script>
<script src=https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js></script><![endif]--></head><body><div id=mobile-navbar class=mobile-navbar><div class=mobile-header-logo><a href=/ class=logo>ODYSSEY</a></div><div class=mobile-navbar-icon><span></span>
<span></span>
<span></span></div></div><nav id=mobile-menu class="mobile-menu slideout-menu"><ul class=mobile-menu-list><li class=mobile-menu-item><a class=menu-item-link href=http://odyssey.halfbit.top/>Home</a></li><li class=mobile-menu-item><a class=menu-item-link href=http://odyssey.halfbit.top/post/>Archives</a></li><li class=mobile-menu-item><a class=menu-item-link href=http://odyssey.halfbit.top/categories/>Categories</a></li><li class=mobile-menu-item><a class=menu-item-link href=http://odyssey.halfbit.top/about/>About</a></li></ul></nav><link rel=stylesheet href=/lib/photoswipe/photoswipe.min.css><link rel=stylesheet href=/lib/photoswipe/default-skin/default-skin.min.css><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)"></button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><header id=header class="header container"><div class=logo-wrapper><a href=/ class=logo>ODYSSEY</a></div><nav class=site-navbar><ul id=menu class=menu><li class=menu-item><a class=menu-item-link href=http://odyssey.halfbit.top/>Home</a></li><li class=menu-item><a class=menu-item-link href=http://odyssey.halfbit.top/post/>Archives</a></li><li class=menu-item><a class=menu-item-link href=http://odyssey.halfbit.top/categories/>Categories</a></li><li class=menu-item><a class=menu-item-link href=http://odyssey.halfbit.top/about/>About</a></li></ul></nav></header><div id=mobile-panel><main id=main class="main bg-llight"><div class=content-wrapper><div id=content class="content container"><article class="post bg-white"><header class=post-header><h1 class=post-title>odor-5k-0</h1><div class=post-meta><time datetime=2022-07-27 class=post-time>2022-07-27</time><div class=post-category><a href=http://odyssey.halfbit.top/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/>论文笔记</a></div></div></header><div class=post-toc id=post-toc><h2 class=post-toc-title>文章目录</h2><div class=post-toc-content><nav id=TableOfContents><ul><li><a href=#aaai2022>AAAI2022</a></li><li><a href=#标签-词向量>标签-词向量</a></li><li><a href=#few-shot>Few Shot</a></li></ul></nav></div></div><div class=post-content><h2 id=aaai2022>AAAI2022</h2><p><strong><a href=https://www.x-mol.com/paperRedirect/1466853195513372672>Inferring Prototypes for Multi-Label Few-Shot Image Classification with Word Vector Guided Attention</a></strong></p><p>（1.标签转为词向量）</p><p>多标签图像分类（ML-IC）+少量图像分类（FSIC）=多标签少量图像分类模型（ML-FSIC）multi-label+few-shot</p><p>动机：不同的标签往往指的是图像的不同部分。例如，给定一个描述汽车和自行车的图像，使用整个图像的表示来获得自行车的原型将是误导的。所以需要一个基于局部图像特征的策略，使我们能够专注于训练图像中最有可能相关的部分。</p><p>然而，由于我们可能只有一些标签的单一训练例子，如果没有某种关于标签含义的先验知识，我们就无法实施这样的策略。为此，我们将依靠词向量（Pennington, Socher, and Manning 2014）。之前一些针对单标签设置的工作已经依靠词向量来直接推断原型（Xing等人，2019；Yan等人，2021a），但由于产生的原型不可避免地有噪音，这种策略在与来自视觉特征的原型结合时最有用。——我的理解：把标签本身的语义作为特征和之前提取的特征图作融合。</p><p>在本文中我们只使用词向量来识别训练图像中哪些区域最有可能与给定的标签相关。13个标签，标签名确实有这方面提示。角膜、结膜。那么这个可不可以做到呢？仅仅依靠词向量就能识别训练图像中哪个区域和当前标签最相关？</p><p>假设我们有一些指代动物的标签。这些标签会有类似的词向量，这就告诉模型，这些不同标签的预测性视觉特征可能是相似的。</p><p><strong>关键点1:同类/同个区域的视觉特征应当有类似的词向量。</strong></p><p>现在，假设我们有一张被标记为猫的图像。根据其他标签的训练数据，该模型将选择可能包含动物的区域（尽管它不一定能够区分猫和密切相关的动物）。</p><p>图像中提取特征-局部特征-全局平均池化-全局特征-投影</p><p>预训练的词向量-投影</p><p>两者共同得到一个joint embedding space。联合embedding空间。这个组件只是用来学习视觉特征和标签的联合embedding。由于损失L cmw的目的是将两种不同的模式（词向量和视觉特征）对齐，我们将其称为跨模式权重损失（CMW-loss）。</p><p>词向量的获取：具体来说，我们使用了从维基百科2014和Gigaword 5中训练出来的向量，这些向量是我们从GloVe项目页面上获得的，网址是https://nlp.stanford.edu/projects/glove。</p><p>![截屏2022-07-27 下午12.26.47](/Users/momochan/Library/Application Support/typora-user-images/截屏2022-07-27 下午12.26.47.png)</p><p>注意力机制：qkv。标签embedding作为query。</p><p>![截屏2022-07-27 下午12.30.51](/Users/momochan/Library/Application Support/typora-user-images/截屏2022-07-27 下午12.30.51.png)</p><p>query images？</p><p>![截屏2022-07-27 下午12.35.52](/Users/momochan/Library/Application Support/typora-user-images/截屏2022-07-27 下午12.35.52.png)</p><h2 id=标签-词向量>标签-词向量</h2><p>13种病变标签：wikipedia（部分找不到，deepl翻译）</p><p>白内障 cataract</p><p>人工晶体 Intraocular lens</p><p>晶状体脱位 Ectopia lentis -> <a href=https://eyewiki.aao.org/Ectopia_Lentis>https://eyewiki.aao.org/Ectopia_Lentis</a></p><p>角膜炎 Keratitis</p><p>角膜瘢痕 Corneal scarring</p><p>角膜变性 Corneal dystrophy（角膜营养不良）</p><p>角结膜肿瘤 Corneal Conjunctival Tumor</p><p>睑裂斑 Palpebral fissure</p><p>翼状胬肉 pterygium</p><p>结膜下出血 subconjunctival hemorrhage</p><p>结膜充血 Conjunctival congestion</p><p>结膜囊肿 Conjunctival cysts</p><p>色素痣 Pigmented nevus</p><p>原文，采用Wikipedia 2014 + Gigaword 5（6B 令牌，400K 词汇，无大小写，300d 向量，822 MB 下载）：<a href=https://huggingface.co/stanfordnlp/glove/resolve/main/glove.6B.zip>glove.6B.zip</a> [ <a href=https://nlp.stanford.edu/data/wordvecs/glove.6B.zip>mirror</a> ]预训练的词向量。</p><p>怎么用呢？</p><p>以及，怎么去</p><p><a href="https://blog.csdn.net/nlpuser/article/details/83627709?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522165889932016782184612764%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fall.%2522%257D&request_id=165889932016782184612764&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_ecpm_v1~pc_rank_34-5-83627709-null-null.142%5Ev35%5Epc_rank_34,185%5Ev2%5Econtrol&utm_term=%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%8D%E5%90%91%E9%87%8F&spm=1018.2226.3001.4187">https://blog.csdn.net/nlpuser/article/details/83627709?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522165889932016782184612764%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fall.%2522%257D&request_id=165889932016782184612764&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_ecpm_v1~pc_rank_34-5-83627709-null-null.142^v35^pc_rank_34,185^v2^control&utm_term=%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%8D%E5%90%91%E9%87%8F&spm=1018.2226.3001.4187</a></p><p>就这样吧……懒得搞了。</p><p>之前说的dynamic mlp：</p><p><a href=https://github.com/ylingfeng/DynamicMLP>https://github.com/ylingfeng/DynamicMLP</a></p><p>shift 操作：</p><p><a href=https://www.msra.cn/zh-cn/news/features/aaai-2022>https://www.msra.cn/zh-cn/news/features/aaai-2022</a></p><p>1.标签的语义和文件名语义和图片语义的结合，弱监督的图像定位，借助标签去对图像关注区域做大致定位</p><p>2.标签的类不均衡问题</p><p>3.应该就是一个标签对应一个词向量吧？</p><h2 id=few-shot>Few Shot</h2><p>1是基于表示的原型网络，匹配网络这种就是，学到了不同的表示再进行对比，你就可以理解为metric based</p><p>2是基于策略的，比如maml这种</p><p>这个可以随便找一篇看看related works..</p><p><a href=https://blog.csdn.net/m0_38031488/article/details/85274890>https://blog.csdn.net/m0_38031488/article/details/85274890</a></p><p><a href=https://blog.csdn.net/u014767662/article/details/81670215>https://blog.csdn.net/u014767662/article/details/81670215</a></p><p>support set 很小的数据集，带标签（不足以训练大的神经网络）</p><p>query 拿query和support set依次对比，最接近最相似的</p><p>meta learning 看作一个东西</p><p>lear to learn</p><p>一张就是 one shot</p><p>training set，support set，query</p><p>k-way：support set里面有k个类别（样本均衡的情况下，随着类别数量增加，acc会降低）</p><p>n-shot：每个class有n个样本（样本均衡的情况下，随着每个类别样本数量增加，acc会升高）</p><p>basic idea：1.从一个很大的训练集上学习相似度，可以判断两张图片的相似度（比如imagenet）</p><p>2.将query和support set里面的每一张图片逐一做对比，计算相似度</p><p>omniglot（1600个类 20个样本） 类似mnist（手写数字识别，10 6000）</p><p>50个字母表（不同语言），每个字母表有很多字符，1623个字符。</p><p>每个字符有20个人手写，所以有20个样本。</p><p>![截屏2022-08-12 下午12.38.00](/Users/momochan/Library/Application Support/typora-user-images/截屏2022-08-12 下午12.38.00.png)</p><p>mini imagenet</p><p>100个类别 每个类别600个样本 = 60000</p><p>84*84的小图片</p><p><a href=https://zhuanlan.zhihu.com/p/437414450>https://zhuanlan.zhihu.com/p/437414450</a></p><p>训练孪生网络的两种方式：</p><p>1.pairwise</p><p>![截屏2022-08-12 下午5.53.25](/Users/momochan/Library/Application Support/typora-user-images/截屏2022-08-12 下午5.53.25.png)</p><p>2.triplet loss</p><p>![截屏2022-08-12 下午5.54.06](/Users/momochan/Library/Application Support/typora-user-images/截屏2022-08-12 下午5.54.06.png)</p><p>3.训练完孪生网络以后，可以提取特征，然后比较两张图片，映射成特征向量，比较距离。</p><p>few-shot 的另一种方法：</p><p>在大的数据集上预训练网络，将query和support set在特征空间上的特征向量，拿来做相似度比较（比如cos）</p><p>更具体的：把均值向量做归一化，得到归一向量，其二范数（向量元素绝对值的平方和再开方）均为1.</p><p>![截屏2022-08-12 下午6.10.26](/Users/momochan/Library/Application Support/typora-user-images/截屏2022-08-12 下午6.10.26.png)</p><p>做预测：先把上面得到的表征堆叠起来得到矩阵M，再用query对应的特征向量q和M作Mq，再做softmax。</p><p>![截屏2022-08-12 下午6.14.09](/Users/momochan/截屏/截屏2022-08-12 下午6.14.09.png)</p><p>![截屏2022-08-12 下午6.16.05](/Users/momochan/截屏/截屏2022-08-12 下午6.16.05.png)</p><p>改进：fine-tune 在support set上进行微调（利用support set再训练一个小的分类器）（技巧，把分类器的W初始化为M，b初始化为0）</p><p>![截屏2022-08-12 下午6.22.25](/Users/momochan/截屏/截屏2022-08-12 下午6.22.25.png)</p><p>再训练小分类器的时候，使用entropy regularization</p><p>![截屏2022-08-12 下午6.27.15](/Users/momochan/截屏/截屏2022-08-12 下午6.27.15.png)</p><p>Trick3，把softmax里面的第一项，修改一下。改成cos。</p><p>![截屏2022-08-12 下午6.28.21](/Users/momochan/截屏/截屏2022-08-12 下午6.28.21.png)</p></div><footer class=post-footer><nav class=post-nav><a class=prev href=/post/dynamic_mlp/><i class=iconfont><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="18" height="18"><path d="M691.908486 949.511495l75.369571-89.491197c10.963703-12.998035 10.285251-32.864502-1.499144-44.378743L479.499795 515.267417l277.93508-310.326815c11.338233-12.190647 11.035334-32.285311-.638543-44.850487l-80.46666-86.564541c-11.680017-12.583596-30.356378-12.893658-41.662889-.716314L257.233596 494.235404c-11.332093 12.183484-11.041474 32.266891.657986 44.844348l80.46666 86.564541c1.772366 1.910513 3.706415 3.533476 5.750981 4.877077l306.620399 321.703933C662.505829 963.726242 680.945807 962.528973 691.908486 949.511495z"/></svg></i><span class="prev-text nav-default">dynamic_mlp</span>
<span class="prev-text nav-mobile">上一篇</span></a>
<a class=next href=/post/java/><span class="next-text nav-default">java</span>
<span class="prev-text nav-mobile">下一篇</span>
<i class=iconfont><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="18" height="18"><path d="M332.091514 74.487481l-75.369571 89.491197c-10.963703 12.998035-10.285251 32.864502 1.499144 44.378743l286.278095 300.375162L266.565125 819.058374c-11.338233 12.190647-11.035334 32.285311.638543 44.850487l80.46666 86.564541c11.680017 12.583596 30.356378 12.893658 41.662889.716314l377.434212-421.426145c11.332093-12.183484 11.041474-32.266891-.657986-44.844348l-80.46666-86.564541c-1.772366-1.910513-3.706415-3.533476-5.750981-4.877077L373.270379 71.774697c-11.777231-11.500939-30.216186-10.304694-41.178865 2.712784z"/></svg></i></a></nav></footer></article></div></div></main><footer id=footer class=footer><div class=icon-links><a href=http://odyssey.halfbit.top/index.xml rel="noopener alternate" type=application/rss+xml class=iconfont title=rss target=_blank><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="30" height="30"><path d="M819.157333 1024C819.157333 574.592 449.408 204.8.0 204.8V0c561.706667.0 1024 462.293333 1024 1024H819.157333zM140.416 743.04a140.8 140.8.0 01140.501333 140.586667A140.928 140.928.0 01140.074667 1024C62.72 1024 0 961.109333.0 883.626667S62.933333 743.082667 140.416 743.04zM678.784 1024h-199.04c0-263.210667-216.533333-479.786667-479.744-479.786667v-199.04c372.352.0 678.784 306.517333 678.784 678.826667z"/></svg></a></div><div class=copyright><span class=power-by>Powered by <a class=hexo-link href=https://gohugo.io>Hugo</a></span>
<span class=division>|</span>
<span class=theme-info>Theme - <a class=theme-link href=https://github.com/xianmin/hugo-theme-jane>Jane</a></span>
<span class=copyright-year>&copy;
2022
<span class=heart><i class=iconfont><svg class="icon" viewBox="0 0 1025 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="14" height="14"><path d="M1000.1 247.9c-15.5-37.3-37.6-70.6-65.7-98.9-54.4-54.8-125.8-85-201-85-85.7.0-166 39-221.4 107.4C456.6 103 376.3 64 290.6 64c-75.1.0-146.5 30.4-201.1 85.6-28.2 28.5-50.4 61.9-65.8 99.3-16 38.8-24 79.9-23.6 122.2.7 91.7 40.1 177.2 108.1 234.8 3.1 2.6 6 5.1 8.9 7.8 14.9 13.4 58 52.8 112.6 102.7 93.5 85.5 209.9 191.9 257.5 234.2 7 6.1 15.8 9.5 24.9 9.5 9.2.0 18.1-3.4 24.9-9.5 34.5-30.7 105.8-95.9 181.4-165 74.2-67.8 150.9-138 195.8-178.2 69.5-57.9 109.6-144.4 109.9-237.3.1-42.5-8-83.6-24-122.2z" fill="#8a8a8a"/></svg></i></span><span class=author>momoka</span></span></div></footer><div class=back-to-top id=back-to-top><i class=iconfont><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="35" height="35"><path d="M510.866688 227.694839 95.449397 629.218702h235.761562L329.15309 958.01517h362.40389L691.55698 628.188232l241.942331-3.089361L510.866688 227.694839zM63.840492 63.962777h894.052392v131.813095H63.840492V63.962777zm0 0"/></svg></i></div></div><script type=text/javascript src=/lib/jquery/jquery-3.2.1.min.js></script>
<script type=text/javascript src=/lib/slideout/slideout-1.0.1.min.js></script>
<script type=text/javascript src=/js/main.638251f4230630f0335d8c6748e53a96f94b72670920b60c09a56fdc8bece214.js integrity="sha256-Y4JR9CMGMPAzXYxnSOU6lvlLcmcJILYMCaVv3Ivs4hQ=" crossorigin=anonymous></script>
<script type=text/javascript src=/js/load-photoswipe.js></script>
<script type=text/javascript src=/lib/photoswipe/photoswipe.min.js></script>
<script type=text/javascript src=/lib/photoswipe/photoswipe-ui-default.min.js></script></body></html>