<!doctype html><html lang=zh-cn itemscope itemtype=http://schema.org/WebPage><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><title>细粒度分类方向调研 - ODYSSEY</title><meta name=renderer content="webkit"><meta name=viewport content="width=device-width,initial-scale=1,user-scalable=yes"><meta name=MobileOptimized content="width"><meta name=HandheldFriendly content="true"><meta name=applicable-device content="pc,mobile"><meta name=theme-color content="#f8f5ec"><meta name=msapplication-navbutton-color content="#f8f5ec"><meta name=apple-mobile-web-app-capable content="yes"><meta name=apple-mobile-web-app-status-bar-style content="#f8f5ec"><meta name=mobile-web-app-capable content="yes"><meta name=author content="momo"><meta name=description content="参考资料 1、https://github.com/LionRoarRoar/Awesome-Fine-grained-Visual-Clas"><meta name=generator content="Hugo 0.104.3"><link rel=canonical href=http://odyssey.halfbit.top/post/%E7%BB%86%E7%B2%92%E5%BA%A6%E5%88%86%E7%B1%BB%E6%96%B9%E5%90%91%E8%B0%83%E7%A0%94/><link rel=icon href=/favicon.ico><link rel=stylesheet href=/sass/jane.min.fa4b2b9f31b5c6d0b683db81157a9226e17b06e61911791ab547242a4a0556f2.css integrity="sha256-+ksrnzG1xtC2g9uBFXqSJuF7BuYZEXkatUckKkoFVvI=" media=screen crossorigin=anonymous><meta property="og:title" content="细粒度分类方向调研"><meta property="og:description" content="参考资料 1、https://github.com/LionRoarRoar/Awesome-Fine-grained-Visual-Clas"><meta property="og:type" content="article"><meta property="og:url" content="http://odyssey.halfbit.top/post/%E7%BB%86%E7%B2%92%E5%BA%A6%E5%88%86%E7%B1%BB%E6%96%B9%E5%90%91%E8%B0%83%E7%A0%94/"><meta property="article:section" content="post"><meta property="article:published_time" content="2022-05-17T00:00:00+00:00"><meta property="article:modified_time" content="2022-05-17T00:00:00+00:00"><meta itemprop=name content="细粒度分类方向调研"><meta itemprop=description content="参考资料 1、https://github.com/LionRoarRoar/Awesome-Fine-grained-Visual-Clas"><meta itemprop=datePublished content="2022-05-17T00:00:00+00:00"><meta itemprop=dateModified content="2022-05-17T00:00:00+00:00"><meta itemprop=wordCount content="2094"><meta itemprop=keywords content><meta name=twitter:card content="summary"><meta name=twitter:title content="细粒度分类方向调研"><meta name=twitter:description content="参考资料 1、https://github.com/LionRoarRoar/Awesome-Fine-grained-Visual-Clas"><!--[if lte IE 9]><script src=https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js></script><![endif]--><!--[if lt IE 9]><script src=https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js></script>
<script src=https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js></script><![endif]--></head><body><div id=mobile-navbar class=mobile-navbar><div class=mobile-header-logo><a href=/ class=logo>ODYSSEY</a></div><div class=mobile-navbar-icon><span></span>
<span></span>
<span></span></div></div><nav id=mobile-menu class="mobile-menu slideout-menu"><ul class=mobile-menu-list><li class=mobile-menu-item><a class=menu-item-link href=http://odyssey.halfbit.top/>Home</a></li><li class=mobile-menu-item><a class=menu-item-link href=http://odyssey.halfbit.top/post/>Archives</a></li><li class=mobile-menu-item><a class=menu-item-link href=http://odyssey.halfbit.top/categories/>Categories</a></li><li class=mobile-menu-item><a class=menu-item-link href=http://odyssey.halfbit.top/about/>About</a></li></ul></nav><link rel=stylesheet href=/lib/photoswipe/photoswipe.min.css><link rel=stylesheet href=/lib/photoswipe/default-skin/default-skin.min.css><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)"></button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><header id=header class="header container"><div class=logo-wrapper><a href=/ class=logo>ODYSSEY</a></div><nav class=site-navbar><ul id=menu class=menu><li class=menu-item><a class=menu-item-link href=http://odyssey.halfbit.top/>Home</a></li><li class=menu-item><a class=menu-item-link href=http://odyssey.halfbit.top/post/>Archives</a></li><li class=menu-item><a class=menu-item-link href=http://odyssey.halfbit.top/categories/>Categories</a></li><li class=menu-item><a class=menu-item-link href=http://odyssey.halfbit.top/about/>About</a></li></ul></nav></header><div id=mobile-panel><main id=main class="main bg-llight"><div class=content-wrapper><div id=content class="content container"><article class="post bg-white"><header class=post-header><h1 class=post-title>细粒度分类方向调研</h1><div class=post-meta><time datetime=2022-05-17 class=post-time>2022-05-17</time><div class=post-category><a href=http://odyssey.halfbit.top/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/>论文笔记</a></div></div></header><div class=post-toc id=post-toc><h2 class=post-toc-title>文章目录</h2><div class=post-toc-content><nav id=TableOfContents><ul><li><a href=#参考资料>参考资料</a></li><li><a href=#资料筛选>资料筛选</a></li><li><a href=#通过端到端特征编码进行细粒度识别>通过端到端特征编码进行细粒度识别</a></li></ul></nav></div></div><div class=post-content><h2 id=参考资料>参考资料</h2><p>1、https://github.com/LionRoarRoar/Awesome-Fine-grained-Visual-Classification</p><p>汇总了从2017-2022年的细粒度分类（主要是自然图像上）的一些论文</p><p>2、https://zhuanlan.zhihu.com/p/53611407 （不推荐）</p><p>3、https://zhuanlan.zhihu.com/p/106369520</p><p>4、http://www.weixiushen.com/project/Awesome_FGIA/Awesome_FGIA.html</p><h2 id=资料筛选>资料筛选</h2><p>参考资料4里面，作者把细粒度识别分成3类。</p><p><strong>1、localization-classification subnetworks，包括检测/分割、深层过滤器/激活、attention、transformer、其他。</strong></p><p><strong>2、通过端到端特征编码进行细粒度识别，包括高阶特征交互、具体损失函数、其他。</strong></p><p><strong>3、利用外部信息，包括网络数据、多模态数据、人参与。</strong></p><p>参考资料1里面，作者把细粒度识别分成四类。</p><p>1、By localize and rescale techniques（定位子网络，利用注意力机制、过滤学习等）</p><p>2、By metric learning</p><p>3、By Attention-based methods（有些论文会和1重合）</p><p>4、Transformer-based methods</p><p>粗略地看，参考资料4的分类更加全面和清楚。有些文章是多个领域结合的，比如定位+注意力/transformer。目前倾向于先看端到端特征编码/度量学习/loss方面的文章。</p><h2 id=通过端到端特征编码进行细粒度识别>通过端到端特征编码进行细粒度识别</h2><p><strong>High-order feature interactions</strong></p><ul><li><p><del><a href=http://vis-www.cs.umass.edu/bcnn/docs/bcnn_iccv15.pdf>Bilinear CNN Models for Fine-grained Visual Recognition</a>.</del>
<del>Tsung-Yu Lin, Aruni RoyChowdhury, and Subhransu Maji. <em>ICCV</em>, 2015. <code>[code]</code></del></p></li><li><p><del><a href=https://people.eecs.berkeley.edu/~yg/papers/compact_bilinear.pdf>Compact Bilinear Pooling</a>.</del>
<del>Yang Gao, Oscar Beijbom, Ning Zhang, and Trevor Darrell. <em>CVPR</em>, 2016. <code>[code]</code></del></p></li><li><p><a href=https://vision.cornell.edu/se3/wp-content/uploads/2017/04/cui2017cvpr.pdf>Kernel Pooling for Convolutional Neural Networks</a>.
Yin Cui, Feng Zhou, Jiang Wang, Xiao Liu, Yuanqing Lin, and Serge Belongie. <em>CVPR</em>, 2017.</p></li><li><p><del><a href=http://openaccess.thecvf.com/content_cvpr_2017/papers/Kong_Low-Rank_Bilinear_Pooling_CVPR_2017_paper.pdf>Low-rank Bilinear Pooling for Fine-Grained Classification</a>.</del>
<del>Shu Kong, and Charless Fowlkes. <em>CVPR</em>, 2017. <code>[code]</code></del></p></li><li><p><a href=http://azadproject.ir/wp-content/uploads/2014/07/2017-Higher-order-Integration-of-Hierarchical-Convolutional-Activations-for-Fine-grained.pdf>Higher-order Integration of Hierarchical Convolutional Activations for Fine-Grained Visual Categorization</a>.
Sijia Cai, Wangmeng Zuo, and Lei Zhang. <em>ICCV</em>, 2017. <code>[code]</code></p></li><li><p><a href=http://openaccess.thecvf.com/content_cvpr_2018/papers/Li_Towards_Faster_Training_CVPR_2018_paper.pdf>Towards Faster Training of Global Covariance Pooling Networks by Iterative Matrix Square Root Normalization</a>.
Peihua Li, Jiangtao Xie, Qilong Wang, and Zilin Gao. <em>CVPR</em>, 2018. <code>[code]</code></p></li><li><p><a href=http://openaccess.thecvf.com/content_ECCV_2018/papers/Melih_Engin_DeepKSPD_Learning_Kernel-matrix-based_ECCV_2018_paper.pdf>DeepKSPD: Learning Kernel-matrix-based SPD Representation for Fine-Grained Image Recognition</a>.
Melih Engin, Lei Wang, Luping Zhou, and Xinwang Liu. <em>ECCV</em>, 2018.</p></li><li><p><del><a href=http://openaccess.thecvf.com/content_ECCV_2018/papers/Chaojian_Yu_Hierarchical_Bilinear_Pooling_ECCV_2018_paper.pdf>Hierarchical Bilinear Pooling for Fine-Grained Visual Recognition</a>.</del>
<del>Chaojian Yu, Xinyi Zhao, Qi Zheng, Peng Zhang, and Xinge You. <em>ECCV</em>, 2018. <code>[code]</code></del></p></li><li><p><a href=http://openaccess.thecvf.com/content_ECCV_2018/papers/Xing_Wei_Grassmann_Pooling_for_ECCV_2018_paper.pdf>Grassmann Pooling as Compact Homogeneous Bilinear Pooling for Fine-Grained Visual Classification</a>.
Xing Wei, Yue Zhang, Yihong Gong, Jiawei Zhang, and Nanning Zheng. <em>ECCV</em>, 2018.</p></li><li><p><a href=http://papers.nips.cc/paper/8680-learning-deep-bilinear-transformation-for-fine-grained-image-representation.pdf>Learning Deep Bilinear Transformation for Fine-grained Image Representation</a>.
Heliang Zheng, Jianlong Fu, Zheng-Jun Zha, and Jiebo Luo. <em>NeurIPS</em>, 2019.</p></li><li><p><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9027108">Multi-Objective Matrix Normalization for Fine-Grained Visual Recognition</a>.
Shaobo Min, Hantao Yao, Hongtao Xie, Zheng-Jun Zha, and Yongdong Zhang. <em>IEEE TIP</em>, 2020.</p></li><li><p><a href=https://arxiv.org/pdf/2012.13975.pdf>Power Normalizations in Fine-grained Image, Few-shot Image and Graph Classification</a>.
Piotr Koniusz, Hongguang Zhang. <em>IEEE TPAMI</em>, 2021.</p></li><li><p><a href=https://openaccess.thecvf.com/content/CVPR2021/papers/Zhao_Graph-Based_High-Order_Relation_Discovery_for_Fine-Grained_Recognition_CVPR_2021_paper.pdf>Graph-based High-Order Relation Discovery for Fine-grained Recognition</a>.
Yifan Zhao, Ke Yan, Feiyue Huang, and Jia Li. <em>CVPR</em>, 2021.</p></li></ul><p><strong>Specific loss functions</strong></p><ul><li><p><a href=https://papers.nips.cc/paper/7344-maximum-entropy-fine-grained-classification>Maximum-Entropy Fine Grained Classification</a>.
Abhimanyu Dubey, Otkrist Gupta, Ramesh Raskar, and Nikhil Naik. <em>NeurIPS</em>, 2018.</p></li><li><p><a href=https://openaccess.thecvf.com/content_ECCV_2018/papers/Abhimanyu_Dubey_Improving_Fine-Grained_Visual_ECCV_2018_paper.pdf>Pairwise Confusion for Fine-Grained Visual Classification</a>.
Abhimanyu Dubey, Otkrist Gupta, Pei Guo, Ramesh Raskar, Ryan Farrell, and Nikhil Naik. <em>ECCV</em>, 2018. <code>[code]</code></p></li><li><p><a href=http://openaccess.thecvf.com/content_ECCV_2018/papers/Ming_Sun_Multi-Attention_Multi-Class_Constraint_ECCV_2018_paper.pdf>Multi-Attention Multi-Class Constraint for Fine-grained Image Recognition</a>.
Ming Sun, Yuchen Yuan, Feng Zhou, and Errui Ding. <em>ECCV</em>, 2018. <code>[code]</code></p></li><li><p><a href=https://arxiv.org/pdf/2003.05235.pdf>Channel Interaction Networks for Fine-Grained Image Categorization</a>.
Yu Gao, Xintong Han, Xun Wang, Weilin Huang, and Matthew R. Scott. <em>AAAI</em>, 2020.</p></li><li><p><del><a href=https://arxiv.org/pdf/1912.06842v1.pdf>Fine-grained Recognition: Accounting for Subtle Differences between Similar Classes</a>.</del>
<del>Guolei Sun, Hisham Cholakkal, Salman Khan, Fahad Shahbaz Khan, and Ling Shao. <em>AAAI</em>, 2020.</del></p></li><li><p><del><a href=https://arxiv.org/pdf/2002.10191.pdf>Learning Attentive Pairwise Interaction for Fine-Grained Classification</a>.</del>
<del>Peiqin Zhuang, Yali Wang, and Yu Qiao. <em>AAAI</em>, 2020.</del></p></li><li><p><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9005389">The Devil is in the Channels: Mutual-Channel Loss for Fine-Grained Image Classification</a>.
Dongliang Chang, Yifeng Ding, Jiyang Xie, Ayan Kumar Bhunia, Xiaoxu Li, Zhanyu Ma, Ming Wu, Jun Guo, and Yi-Zhe Song. <em>IEEE TIP</em>, 2020.</p></li></ul><p>(中文)</p><p><strong>高阶特征交互</strong></p><ul><li><p><a href=http://vis-www.cs.umass.edu/bcnn/docs/bcnn_iccv15.pdf>用于细粒度视觉识别的双线性 CNN 模型</a>。
Tsung-Yu Lin、Aruni RoyChowdhury 和 Subhransu Maji。<em>ICCV</em> , 2015. <code>[代码]</code></p></li><li><p><a href=https://people.eecs.berkeley.edu/~yg/papers/compact_bilinear.pdf>紧凑型双线性池</a>。
高阳、奥斯卡·贝博姆、张宁和特雷弗·达雷尔。<em>CVPR</em> , 2016. <code>[代码]</code></p></li><li><p><a href=https://vision.cornell.edu/se3/wp-content/uploads/2017/04/cui2017cvpr.pdf>卷积神经网络的内核池化</a>。
崔寅、冯周、江旺、小刘、林元庆和塞尔吉·贝隆吉。<em>简历</em>，2017 年。</p></li><li><p><a href=http://openaccess.thecvf.com/content_cvpr_2017/papers/Kong_Low-Rank_Bilinear_Pooling_CVPR_2017_paper.pdf>用于细粒度分类的低秩双线性池</a>。
Shu Kong 和 Charless Fowlkes。<em>CVPR</em> , 2017. <code>[代码]</code></p></li><li><p><a href=http://azadproject.ir/wp-content/uploads/2014/07/2017-Higher-order-Integration-of-Hierarchical-Convolutional-Activations-for-Fine-grained.pdf>用于细粒度视觉分类的层次卷积激活的高阶集成</a>。
蔡思佳、左王梦、张磊。<em>ICCV</em> , 2017. <code>[代码]</code></p></li><li><p><a href=http://openaccess.thecvf.com/content_cvpr_2018/papers/Li_Towards_Faster_Training_CVPR_2018_paper.pdf>通过迭代矩阵平方根归一化加快全局协方差池网络的训练</a>。
李培华，谢江涛，王启龙，高梓琳。<em>CVPR</em> , 2018. <code>[代码]</code></p></li><li><p><a href=http://openaccess.thecvf.com/content_ECCV_2018/papers/Melih_Engin_DeepKSPD_Learning_Kernel-matrix-based_ECCV_2018_paper.pdf>DeepKSPD：学习用于细粒度图像识别的基于内核矩阵的 SPD 表示</a>。
Melih Engin、Lei Wang、Luping Zhou 和 Xinwang Liu。<em>欧共体</em>，2018。</p></li><li><p><a href=http://openaccess.thecvf.com/content_ECCV_2018/papers/Chaojian_Yu_Hierarchical_Bilinear_Pooling_ECCV_2018_paper.pdf>用于细粒度视觉识别的分层双线性池</a>。
于超建、赵信义、齐政、张鹏、游新歌。<em>ECCV</em> , 2018. <code>[代码]</code></p></li><li><p><a href=http://openaccess.thecvf.com/content_ECCV_2018/papers/Xing_Wei_Grassmann_Pooling_for_ECCV_2018_paper.pdf>Grassmann 池化作为用于细粒度视觉分类的紧凑同质双线性池</a>。
邢伟、张悦、龚一红、张家伟、郑南宁。<em>欧共体</em>，2018。</p></li><li><p><a href=http://papers.nips.cc/paper/8680-learning-deep-bilinear-transformation-for-fine-grained-image-representation.pdf>学习用于细粒度图像表示的深度双线性变换</a>。
郑和良、傅建龙、查正军、罗洁波。<em>神经系统</em>，2019。</p></li><li><p><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9027108">用于细粒度视觉识别的多目标矩阵归一化</a>。
闵少波、姚涵涛、谢洪涛、查正军、张永东。<em>IEEE 提示</em>，2020。</p></li><li><p><a href=https://arxiv.org/pdf/2012.13975.pdf>细粒度图像、少镜头图像和图形分类中的功率归一化</a>。
Piotr Koniusz，张宏光。<em>IEEE TPAMI</em>，2021 年。</p></li><li><p><a href=https://openaccess.thecvf.com/content/CVPR2021/papers/Zhao_Graph-Based_High-Order_Relation_Discovery_for_Fine-Grained_Recognition_CVPR_2021_paper.pdf>用于细粒度识别的基于图的高阶关系发现</a>。
赵亦凡、柯彦、黄飞跃、李佳。<em>简历</em>，2021 年。</p></li></ul><p><strong>具体损失函数</strong></p><ul><li><p><a href=https://papers.nips.cc/paper/7344-maximum-entropy-fine-grained-classification>最大熵细粒度分类</a>。
Abhimanyu Dubey、Otkrist Gupta、Ramesh Raskar 和 Nikhil Naik。<em>神经系统</em>，2018。</p></li><li><p><a href=https://openaccess.thecvf.com/content_ECCV_2018/papers/Abhimanyu_Dubey_Improving_Fine-Grained_Visual_ECCV_2018_paper.pdf>细粒度视觉分类的成对混淆</a>。
Abhimanyu Dubey、Otkrist Gupta、Pei Guo、Ramesh Raskar、Ryan Farrell 和 Nikhil Naik。<em>ECCV</em> , 2018. <code>[代码]</code></p></li><li><p><a href=http://openaccess.thecvf.com/content_ECCV_2018/papers/Ming_Sun_Multi-Attention_Multi-Class_Constraint_ECCV_2018_paper.pdf>细粒度图像识别的多注意多类约束</a>。
孙明、袁雨辰、周丰、丁二瑞。<em>ECCV</em> , 2018. <code>[代码]</code></p></li><li><p><a href=https://arxiv.org/pdf/2003.05235.pdf>用于细粒度图像分类的通道交互网络</a>。
于高、韩新彤、王迅、黄伟林和马修·R·斯科特。<em>美国人工智能学会</em>，2020。</p></li><li><p><a href=https://arxiv.org/pdf/1912.06842v1.pdf>细粒度识别：解释相似类之间的细微差异</a>。
孙国磊、希沙姆·乔拉卡尔、萨尔曼·汗、法赫德·沙赫巴兹·汗和凌绍。<em>美国人工智能学会</em>，2020。</p></li><li><p><a href=https://arxiv.org/pdf/2002.10191.pdf>学习细粒度分类的注意配对交互</a>。
庄培钦、王雅丽、于乔。<em>美国人工智能学会</em>，2020。</p></li><li><p><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9005389">通道中的魔鬼：细粒度图像分类的互通道损失</a>。
常栋梁、丁一峰、谢继阳、Ayan Kumar Bhunia、李晓旭、马占宇、吴明、郭俊和宋一哲。<em>IEEE 提示</em>，2020。</p></li></ul></div><footer class=post-footer><nav class=post-nav><a class=prev href=/post/api-net/><i class=iconfont><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="18" height="18"><path d="M691.908486 949.511495l75.369571-89.491197c10.963703-12.998035 10.285251-32.864502-1.499144-44.378743L479.499795 515.267417l277.93508-310.326815c11.338233-12.190647 11.035334-32.285311-.638543-44.850487l-80.46666-86.564541c-11.680017-12.583596-30.356378-12.893658-41.662889-.716314L257.233596 494.235404c-11.332093 12.183484-11.041474 32.266891.657986 44.844348l80.46666 86.564541c1.772366 1.910513 3.706415 3.533476 5.750981 4.877077l306.620399 321.703933C662.505829 963.726242 680.945807 962.528973 691.908486 949.511495z"/></svg></i><span class="prev-text nav-default">API-NET论文笔记</span>
<span class="prev-text nav-mobile">上一篇</span></a>
<a class=next href=/post/arxiv%E9%80%9F%E8%A7%88/><span class="next-text nav-default">arxiv速览</span>
<span class="prev-text nav-mobile">下一篇</span>
<i class=iconfont><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="18" height="18"><path d="M332.091514 74.487481l-75.369571 89.491197c-10.963703 12.998035-10.285251 32.864502 1.499144 44.378743l286.278095 300.375162L266.565125 819.058374c-11.338233 12.190647-11.035334 32.285311.638543 44.850487l80.46666 86.564541c11.680017 12.583596 30.356378 12.893658 41.662889.716314l377.434212-421.426145c11.332093-12.183484 11.041474-32.266891-.657986-44.844348l-80.46666-86.564541c-1.772366-1.910513-3.706415-3.533476-5.750981-4.877077L373.270379 71.774697c-11.777231-11.500939-30.216186-10.304694-41.178865 2.712784z"/></svg></i></a></nav></footer></article></div></div></main><footer id=footer class=footer><div class=icon-links><a href=http://odyssey.halfbit.top/index.xml rel="noopener alternate" type=application/rss+xml class=iconfont title=rss target=_blank><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="30" height="30"><path d="M819.157333 1024C819.157333 574.592 449.408 204.8.0 204.8V0c561.706667.0 1024 462.293333 1024 1024H819.157333zM140.416 743.04a140.8 140.8.0 01140.501333 140.586667A140.928 140.928.0 01140.074667 1024C62.72 1024 0 961.109333.0 883.626667S62.933333 743.082667 140.416 743.04zM678.784 1024h-199.04c0-263.210667-216.533333-479.786667-479.744-479.786667v-199.04c372.352.0 678.784 306.517333 678.784 678.826667z"/></svg></a></div><div class=copyright><span class=power-by>Powered by <a class=hexo-link href=https://gohugo.io>Hugo</a></span>
<span class=division>|</span>
<span class=theme-info>Theme - <a class=theme-link href=https://github.com/xianmin/hugo-theme-jane>Jane</a></span>
<span class=copyright-year>&copy;
2022
<span class=heart><i class=iconfont><svg class="icon" viewBox="0 0 1025 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="14" height="14"><path d="M1000.1 247.9c-15.5-37.3-37.6-70.6-65.7-98.9-54.4-54.8-125.8-85-201-85-85.7.0-166 39-221.4 107.4C456.6 103 376.3 64 290.6 64c-75.1.0-146.5 30.4-201.1 85.6-28.2 28.5-50.4 61.9-65.8 99.3-16 38.8-24 79.9-23.6 122.2.7 91.7 40.1 177.2 108.1 234.8 3.1 2.6 6 5.1 8.9 7.8 14.9 13.4 58 52.8 112.6 102.7 93.5 85.5 209.9 191.9 257.5 234.2 7 6.1 15.8 9.5 24.9 9.5 9.2.0 18.1-3.4 24.9-9.5 34.5-30.7 105.8-95.9 181.4-165 74.2-67.8 150.9-138 195.8-178.2 69.5-57.9 109.6-144.4 109.9-237.3.1-42.5-8-83.6-24-122.2z" fill="#8a8a8a"/></svg></i></span><span class=author>momoka</span></span></div></footer><div class=back-to-top id=back-to-top><i class=iconfont><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="35" height="35"><path d="M510.866688 227.694839 95.449397 629.218702h235.761562L329.15309 958.01517h362.40389L691.55698 628.188232l241.942331-3.089361L510.866688 227.694839zM63.840492 63.962777h894.052392v131.813095H63.840492V63.962777zm0 0"/></svg></i></div></div><script type=text/javascript src=/lib/jquery/jquery-3.2.1.min.js></script>
<script type=text/javascript src=/lib/slideout/slideout-1.0.1.min.js></script>
<script type=text/javascript src=/js/main.638251f4230630f0335d8c6748e53a96f94b72670920b60c09a56fdc8bece214.js integrity="sha256-Y4JR9CMGMPAzXYxnSOU6lvlLcmcJILYMCaVv3Ivs4hQ=" crossorigin=anonymous></script>
<script type=text/javascript src=/js/load-photoswipe.js></script>
<script type=text/javascript src=/lib/photoswipe/photoswipe.min.js></script>
<script type=text/javascript src=/lib/photoswipe/photoswipe-ui-default.min.js></script></body></html>