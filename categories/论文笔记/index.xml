<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>论文笔记 on ODYSSEY</title><link>http://odyssey.halfbit.top/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/</link><description>Recent content in 论文笔记 on ODYSSEY</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><lastBuildDate>Mon, 23 May 2022 00:00:00 +0000</lastBuildDate><atom:link href="http://odyssey.halfbit.top/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/index.xml" rel="self" type="application/rss+xml"/><item><title>luna论文笔记</title><link>http://odyssey.halfbit.top/post/luna%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/</link><pubDate>Mon, 23 May 2022 00:00:00 +0000</pubDate><guid>http://odyssey.halfbit.top/post/luna%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/</guid><description>LUNA: Localizing Unfamiliarity Near Acquaintance for Open-set Long-Tailed Recognition https://www.aaai.org/AAAI22Papers/AAAI-10200.CaiJ.pdf 2022 AAAI 博客 center loss： https://blog.csdn.net/duan19920101/article/details/104445423 https://github.com/KaiyangZhou/pytorch-center-loss （center_loss.py） 动机 However, the performances of the state-of-the-art object recognition methods mostly bias on the sample-rich classes that have been seen in the training set, with a limited ability on classifying the</description></item><item><title>WS-DAN论文笔记</title><link>http://odyssey.halfbit.top/post/ws-dan%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/</link><pubDate>Sat, 21 May 2022 00:00:00 +0000</pubDate><guid>http://odyssey.halfbit.top/post/ws-dan%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/</guid><description>我的启发 之前看过这篇文章。跑了代码以后，再重新看一遍并且详细记录一下自己的理解。 引用 See Better Before Looking Closer: Weakly Supervised Data Augmentation Network for Fine-Grained Visual Classification, https://arxiv.org/pdf/1901.09891.pdf. 相关博客 https://blog.csdn.net/weixin_41735859/article/details/108417343 摘要 数据增强可以</description></item><item><title>API-NET论文笔记</title><link>http://odyssey.halfbit.top/post/api-net/</link><pubDate>Tue, 17 May 2022 00:00:00 +0000</pubDate><guid>http://odyssey.halfbit.top/post/api-net/</guid><description>我的启发 1、图像成对输入的写法。2、两个不同图像的一种交互方式。3、生成注意力的计算方法。 引用 Learning Attentive Pairwise Interaction for Fine-Grained Classification, AAAI, 2020, https://arxiv.org/abs/2002.10191. 博客 https://mp.weixin.qq.com/s/RrMxbnoTPtbHKduNPIvI8g https://blog.csdn.net/qq_34317565/article/details/108028839?csdn_share_tail=%7B%22type%22%3A%22blog%22%2C%22rType%22%3A%22article%22%2C%22rId%22%3A%22108028839%22%2C%22source%22%3A%22momoka9%22%7D&amp;amp;ctrtid=bXigX 简介 Attentive Pairwise Interaction Network (AP</description></item><item><title>细粒度分类方向调研</title><link>http://odyssey.halfbit.top/post/%E7%BB%86%E7%B2%92%E5%BA%A6%E5%88%86%E7%B1%BB%E6%96%B9%E5%90%91%E8%B0%83%E7%A0%94/</link><pubDate>Tue, 17 May 2022 00:00:00 +0000</pubDate><guid>http://odyssey.halfbit.top/post/%E7%BB%86%E7%B2%92%E5%BA%A6%E5%88%86%E7%B1%BB%E6%96%B9%E5%90%91%E8%B0%83%E7%A0%94/</guid><description>参考资料 1、https://github.com/LionRoarRoar/Awesome-Fine-grained-Visual-Clas</description></item><item><title>arxiv速览</title><link>http://odyssey.halfbit.top/post/arxiv%E9%80%9F%E8%A7%88/</link><pubDate>Thu, 12 May 2022 00:00:00 +0000</pubDate><guid>http://odyssey.halfbit.top/post/arxiv%E9%80%9F%E8%A7%88/</guid><description>1篇arxiv最新的摘要和关键词提取（分类/分割相关）（5.6-5.12） 1、Robust Medical Image Classification from Noisy Labeled Data with Global and Local Representation Guided Co-training 全局和局部表示引导联合</description></item><item><title>mobile net</title><link>http://odyssey.halfbit.top/post/mobilenet/</link><pubDate>Thu, 12 May 2022 00:00:00 +0000</pubDate><guid>http://odyssey.halfbit.top/post/mobilenet/</guid><description>MobileNet V1 MobileNets是为移动和嵌入式设备提出的高效模型。MobileNets基于流线型架构(streamlined)，使用深度可分离卷积</description></item><item><title>CL_PLP论文笔记</title><link>http://odyssey.halfbit.top/post/cl_plp/</link><pubDate>Wed, 11 May 2022 00:00:00 +0000</pubDate><guid>http://odyssey.halfbit.top/post/cl_plp/</guid><description>Deep semi-supervised learning with contrastive learning and partial label propagation for image data https://www.sciencedirect.com/science/article/pii/S0950705122002702 在本文中，我们提出了一种新的基于对比性自监督学习和部分标签传播策略的深度半监督学习算法，称为CL_PLP。该方法</description></item><item><title>自监督med论文笔记</title><link>http://odyssey.halfbit.top/post/%E8%87%AA%E7%9B%91%E7%9D%A3med%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/</link><pubDate>Wed, 11 May 2022 00:00:00 +0000</pubDate><guid>http://odyssey.halfbit.top/post/%E8%87%AA%E7%9B%91%E7%9D%A3med%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/</guid><description>Momentum contrastive learning for few-shot COVID-19 diagnosis from chest CT images https://www.sciencedirect.com/science/article/pii/S0031320321000133?via%3Dihub 2021 pattern recognition 作者开发了一个端到端的可训练的深度few-shot学习框架，可以在胸部CT图像上以最少的训练提供准确的预测。具</description></item><item><title>对比学习相关和思考</title><link>http://odyssey.halfbit.top/post/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E7%9B%B8%E5%85%B3/</link><pubDate>Mon, 09 May 2022 00:00:00 +0000</pubDate><guid>http://odyssey.halfbit.top/post/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E7%9B%B8%E5%85%B3/</guid><description>ContrastiveCrop Crafting Better Contrastive Views for Siamese Representation Learning CVPR 2022 Paper: https://arxiv.org/abs/2202.03278 Code: https://github.com/xyupeng/ContrastiveCrop 中文解读：https://mp.weixin.qq.com/s/VTP9D5f7KG9vg30U9kVI2A 动</description></item><item><title>基于对比学习的计算性组织病理学预测癌症驱动基因的差异性表达</title><link>http://odyssey.halfbit.top/post/%E5%9F%BA%E4%BA%8E%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E7%9A%84%E8%AE%A1%E7%AE%97%E6%80%A7%E7%BB%84%E7%BB%87%E7%97%85%E7%90%86%E5%AD%A6%E9%A2%84%E6%B5%8B%E7%99%8C%E7%97%87%E9%A9%B1%E5%8A%A8%E5%9F%BA%E5%9B%A0%E7%9A%84%E5%B7%AE%E5%BC%82%E6%80%A7%E8%A1%A8%E8%BE%BE/</link><pubDate>Sun, 08 May 2022 00:00:00 +0000</pubDate><guid>http://odyssey.halfbit.top/post/%E5%9F%BA%E4%BA%8E%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E7%9A%84%E8%AE%A1%E7%AE%97%E6%80%A7%E7%BB%84%E7%BB%87%E7%97%85%E7%90%86%E5%AD%A6%E9%A2%84%E6%B5%8B%E7%99%8C%E7%97%87%E9%A9%B1%E5%8A%A8%E5%9F%BA%E5%9B%A0%E7%9A%84%E5%B7%AE%E5%BC%82%E6%80%A7%E8%A1%A8%E8%BE%BE/</guid><description>我的启发 因为是比较新的刚挂上arxiv的文章，内容刚好也是病理图像+对比学习无监督预训练，所以拿来参考一下思路。启发：1.这里提到AdCo，</description></item></channel></rss>